{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: 根据已有数据创建神经网络ANN\n",
    "'''\n",
    "conda create -n myenv python=3.8\n",
    "conda activate myenv\n",
    "\n",
    "conda install numpy pandas scikit-learn\n",
    "conda install -c conda-forge tensorflow\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the Clark-Y airfoil database \n",
    "# Reynolds: 1000-1000000, Mach: 0.1-0.7, and AOA: -3-15 degrees\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r'E:\\airfoil_tools\\airfoil_ann\\input\\clark-y-3.csv')\n",
    "\n",
    "# Filter the data\n",
    "filtered_df = df[\n",
    "    (df['Reynold'] >= 0.1e4) & (df['Reynold'] <= 10e5) &  # 雷诺数范围\n",
    "    (df['Mach'] >= 0.1) & (df['Mach'] <= 0.7) &            # 马赫数范围\n",
    "    (df['Alpha'] >= -3) & (df['Alpha'] <= 15)              # 迎角范围\n",
    "]\n",
    "\n",
    "# Split the data into inputs (X) and outputs (y)\n",
    "X = filtered_df[['Reynold', 'Mach', 'Alpha']].values\n",
    "y = filtered_df[['cl', 'cd', 'cm']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "240/240 [==============================] - 2s 5ms/step - loss: 0.0414 - mae: 0.1640 - val_loss: 0.0315 - val_mae: 0.1445\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0216 - mae: 0.1121 - val_loss: 0.0146 - val_mae: 0.0875\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0113 - mae: 0.0753 - val_loss: 0.0091 - val_mae: 0.0685\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0610 - val_loss: 0.0061 - val_mae: 0.0558\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0051 - mae: 0.0516 - val_loss: 0.0045 - val_mae: 0.0480\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0457 - val_loss: 0.0039 - val_mae: 0.0452\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0035 - mae: 0.0416 - val_loss: 0.0033 - val_mae: 0.0401\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0032 - mae: 0.0393 - val_loss: 0.0029 - val_mae: 0.0376\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0376 - val_loss: 0.0028 - val_mae: 0.0366\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0024 - val_mae: 0.0343\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0023 - val_mae: 0.0337\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0021 - val_mae: 0.0330\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0299 - val_loss: 0.0018 - val_mae: 0.0284\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0015 - val_mae: 0.0259\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0014 - val_mae: 0.0245\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0241\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 8.6449e-04 - val_mae: 0.0195\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 8.9041e-04 - mae: 0.0197 - val_loss: 9.4782e-04 - val_mae: 0.0205\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 8.4523e-04 - mae: 0.0193 - val_loss: 7.8711e-04 - val_mae: 0.0191\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 8.0437e-04 - mae: 0.0187 - val_loss: 7.0977e-04 - val_mae: 0.0176\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 7.8615e-04 - mae: 0.0185 - val_loss: 7.5627e-04 - val_mae: 0.0185\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 7.2151e-04 - mae: 0.0175 - val_loss: 7.4136e-04 - val_mae: 0.0183\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 7.3069e-04 - mae: 0.0177 - val_loss: 6.0413e-04 - val_mae: 0.0155\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 6.9746e-04 - mae: 0.0171 - val_loss: 6.4926e-04 - val_mae: 0.0168\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 6.6293e-04 - mae: 0.0167 - val_loss: 8.1072e-04 - val_mae: 0.0199\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 6.6130e-04 - mae: 0.0167 - val_loss: 5.9856e-04 - val_mae: 0.0154\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 6.1026e-04 - mae: 0.0157 - val_loss: 6.7491e-04 - val_mae: 0.0171\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 6.0793e-04 - mae: 0.0159 - val_loss: 5.7906e-04 - val_mae: 0.0154\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 6.3415e-04 - mae: 0.0164 - val_loss: 5.7010e-04 - val_mae: 0.0149\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.9379e-04 - mae: 0.0157 - val_loss: 6.5212e-04 - val_mae: 0.0171\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.6887e-04 - mae: 0.0153 - val_loss: 6.3269e-04 - val_mae: 0.0169\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.7090e-04 - mae: 0.0153 - val_loss: 5.5919e-04 - val_mae: 0.0154\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 5.4506e-04 - mae: 0.0148 - val_loss: 5.3517e-04 - val_mae: 0.0150\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 5.2790e-04 - mae: 0.0145 - val_loss: 5.8703e-04 - val_mae: 0.0159\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.1674e-04 - mae: 0.0143 - val_loss: 4.8205e-04 - val_mae: 0.0137\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 5.5119e-04 - mae: 0.0150 - val_loss: 6.6303e-04 - val_mae: 0.0173\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 5.0288e-04 - mae: 0.0141 - val_loss: 4.6972e-04 - val_mae: 0.0134\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.0401e-04 - mae: 0.0140 - val_loss: 6.4952e-04 - val_mae: 0.0181\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.9784e-04 - mae: 0.0141 - val_loss: 4.3069e-04 - val_mae: 0.0131\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.6636e-04 - mae: 0.0135 - val_loss: 4.9381e-04 - val_mae: 0.0145\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.5930e-04 - mae: 0.0133 - val_loss: 4.8998e-04 - val_mae: 0.0138\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 4.6809e-04 - mae: 0.0138 - val_loss: 4.0037e-04 - val_mae: 0.0124\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.3908e-04 - mae: 0.0129 - val_loss: 4.1246e-04 - val_mae: 0.0125\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.4281e-04 - mae: 0.0130 - val_loss: 5.0177e-04 - val_mae: 0.0132\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.2690e-04 - mae: 0.0129 - val_loss: 3.7085e-04 - val_mae: 0.0118\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.3090e-04 - mae: 0.0129 - val_loss: 4.8364e-04 - val_mae: 0.0148\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 4.2153e-04 - mae: 0.0129 - val_loss: 3.9264e-04 - val_mae: 0.0127\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.1510e-04 - mae: 0.0128 - val_loss: 3.3129e-04 - val_mae: 0.0110\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.8397e-04 - mae: 0.0120 - val_loss: 3.8977e-04 - val_mae: 0.0128\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.7995e-04 - mae: 0.0120 - val_loss: 3.2253e-04 - val_mae: 0.0107\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.7668e-04 - mae: 0.0120 - val_loss: 3.3278e-04 - val_mae: 0.0109\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.7241e-04 - mae: 0.0119 - val_loss: 3.4386e-04 - val_mae: 0.0114\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.7837e-04 - mae: 0.0120 - val_loss: 5.9157e-04 - val_mae: 0.0178\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.9765e-04 - mae: 0.0125 - val_loss: 3.8201e-04 - val_mae: 0.0135\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.6988e-04 - mae: 0.0119 - val_loss: 3.0568e-04 - val_mae: 0.0112\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 3.7453e-04 - mae: 0.0121 - val_loss: 3.2170e-04 - val_mae: 0.0118\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.6519e-04 - mae: 0.0118 - val_loss: 2.8489e-04 - val_mae: 0.0104\n",
      "Epoch 60/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.4256e-04 - mae: 0.0114 - val_loss: 3.7108e-04 - val_mae: 0.0137\n",
      "Epoch 61/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.6808e-04 - mae: 0.0120 - val_loss: 3.2402e-04 - val_mae: 0.0110\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.7824e-04 - mae: 0.0121 - val_loss: 3.9124e-04 - val_mae: 0.0136\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.5934e-04 - mae: 0.0118 - val_loss: 3.5274e-04 - val_mae: 0.0125\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.4691e-04 - mae: 0.0114 - val_loss: 2.7017e-04 - val_mae: 0.0103\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.5162e-04 - mae: 0.0117 - val_loss: 2.9163e-04 - val_mae: 0.0104\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.2429e-04 - mae: 0.0110 - val_loss: 3.2338e-04 - val_mae: 0.0123\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.3973e-04 - mae: 0.0113 - val_loss: 3.0218e-04 - val_mae: 0.0112\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.2486e-04 - mae: 0.0110 - val_loss: 3.1182e-04 - val_mae: 0.0115\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.3311e-04 - mae: 0.0112 - val_loss: 2.7450e-04 - val_mae: 0.0106\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.2791e-04 - mae: 0.0110 - val_loss: 3.6803e-04 - val_mae: 0.0123\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.1984e-04 - mae: 0.0108 - val_loss: 5.6043e-04 - val_mae: 0.0161\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.4308e-04 - mae: 0.0114 - val_loss: 2.6954e-04 - val_mae: 0.0105\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.1979e-04 - mae: 0.0109 - val_loss: 2.6511e-04 - val_mae: 0.0102\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.0313e-04 - mae: 0.0107 - val_loss: 2.7298e-04 - val_mae: 0.0102\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.0567e-04 - mae: 0.0105 - val_loss: 3.3412e-04 - val_mae: 0.0127\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.2912e-04 - mae: 0.0112 - val_loss: 2.8247e-04 - val_mae: 0.0111\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9648e-04 - mae: 0.0104 - val_loss: 2.9404e-04 - val_mae: 0.0100\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.5452e-04 - mae: 0.0116 - val_loss: 3.1989e-04 - val_mae: 0.0115\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.9625e-04 - mae: 0.0104 - val_loss: 3.0838e-04 - val_mae: 0.0121\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 3.0414e-04 - mae: 0.0106 - val_loss: 2.8275e-04 - val_mae: 0.0105\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 3.2681e-04 - mae: 0.0112 - val_loss: 2.4843e-04 - val_mae: 0.0094\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.2142e-04 - mae: 0.0109 - val_loss: 2.3162e-04 - val_mae: 0.0094\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.8233e-04 - mae: 0.0100 - val_loss: 3.2325e-04 - val_mae: 0.0125\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9026e-04 - mae: 0.0105 - val_loss: 2.5073e-04 - val_mae: 0.0098\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 3.1460e-04 - mae: 0.0110 - val_loss: 3.4190e-04 - val_mae: 0.0108\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.9983e-04 - mae: 0.0105 - val_loss: 3.9503e-04 - val_mae: 0.0136\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9782e-04 - mae: 0.0105 - val_loss: 2.9937e-04 - val_mae: 0.0109\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9390e-04 - mae: 0.0104 - val_loss: 2.3425e-04 - val_mae: 0.0097\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.7494e-04 - mae: 0.0100 - val_loss: 2.2221e-04 - val_mae: 0.0088\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.8599e-04 - mae: 0.0105 - val_loss: 2.9008e-04 - val_mae: 0.0115\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9944e-04 - mae: 0.0104 - val_loss: 2.5983e-04 - val_mae: 0.0109\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9258e-04 - mae: 0.0104 - val_loss: 4.3451e-04 - val_mae: 0.0154\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.8330e-04 - mae: 0.0102 - val_loss: 1.9939e-04 - val_mae: 0.0084\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.9971e-04 - mae: 0.0107 - val_loss: 3.2509e-04 - val_mae: 0.0121\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.9636e-04 - mae: 0.0105 - val_loss: 2.7467e-04 - val_mae: 0.0102\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.7710e-04 - mae: 0.0098 - val_loss: 1.9508e-04 - val_mae: 0.0084\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.9881e-04 - mae: 0.0106 - val_loss: 3.7956e-04 - val_mae: 0.0135\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.8959e-04 - mae: 0.0103 - val_loss: 2.4169e-04 - val_mae: 0.0100\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.7712e-04 - mae: 0.0100 - val_loss: 2.6253e-04 - val_mae: 0.0110\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.6264e-04 - mae: 0.0098 - val_loss: 4.0783e-04 - val_mae: 0.0130\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.6164e-04 - mae: 0.0095 - val_loss: 2.3881e-04 - val_mae: 0.0097\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.6009e-04 - mae: 0.0097 - val_loss: 2.3334e-04 - val_mae: 0.0089\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.8988e-04 - mae: 0.0101 - val_loss: 4.3723e-04 - val_mae: 0.0140\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.8684e-04 - mae: 0.0103 - val_loss: 2.6969e-04 - val_mae: 0.0100\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.9678e-04 - mae: 0.0104 - val_loss: 2.1904e-04 - val_mae: 0.0092\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.6897e-04 - mae: 0.0100 - val_loss: 2.2628e-04 - val_mae: 0.0095\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.7065e-04 - mae: 0.0098 - val_loss: 2.9049e-04 - val_mae: 0.0107\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5855e-04 - mae: 0.0097 - val_loss: 1.9092e-04 - val_mae: 0.0085\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.4179e-04 - mae: 0.0091 - val_loss: 1.9537e-04 - val_mae: 0.0084\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4246e-04 - mae: 0.0092 - val_loss: 2.4179e-04 - val_mae: 0.0095\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.8865e-04 - mae: 0.0103 - val_loss: 6.0447e-04 - val_mae: 0.0167\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 3.0099e-04 - mae: 0.0106 - val_loss: 2.8749e-04 - val_mae: 0.0108\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.6973e-04 - mae: 0.0097 - val_loss: 2.0846e-04 - val_mae: 0.0094\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4563e-04 - mae: 0.0094 - val_loss: 2.1079e-04 - val_mae: 0.0090\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.4367e-04 - mae: 0.0092 - val_loss: 2.2498e-04 - val_mae: 0.0086\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.6019e-04 - mae: 0.0096 - val_loss: 2.3137e-04 - val_mae: 0.0097\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.4969e-04 - mae: 0.0094 - val_loss: 1.8808e-04 - val_mae: 0.0083\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.6837e-04 - mae: 0.0101 - val_loss: 2.1145e-04 - val_mae: 0.0087\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3668e-04 - mae: 0.0091 - val_loss: 2.3305e-04 - val_mae: 0.0100\n",
      "Epoch 120/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3925e-04 - mae: 0.0092 - val_loss: 1.8431e-04 - val_mae: 0.0082\n",
      "Epoch 121/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.5446e-04 - mae: 0.0097 - val_loss: 2.1324e-04 - val_mae: 0.0089\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4436e-04 - mae: 0.0093 - val_loss: 2.0625e-04 - val_mae: 0.0090\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4303e-04 - mae: 0.0093 - val_loss: 1.7661e-04 - val_mae: 0.0081\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5454e-04 - mae: 0.0097 - val_loss: 2.4131e-04 - val_mae: 0.0101\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5306e-04 - mae: 0.0097 - val_loss: 1.9793e-04 - val_mae: 0.0092\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0811e-04 - mae: 0.0084 - val_loss: 2.6570e-04 - val_mae: 0.0106\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5817e-04 - mae: 0.0097 - val_loss: 1.7721e-04 - val_mae: 0.0079\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.3869e-04 - mae: 0.0093 - val_loss: 1.7670e-04 - val_mae: 0.0082\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.4029e-04 - mae: 0.0091 - val_loss: 2.2447e-04 - val_mae: 0.0096\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.6768e-04 - mae: 0.0101 - val_loss: 1.6466e-04 - val_mae: 0.0075\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.2673e-04 - mae: 0.0089 - val_loss: 1.6490e-04 - val_mae: 0.0076\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.2416e-04 - mae: 0.0089 - val_loss: 2.2146e-04 - val_mae: 0.0095\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.3815e-04 - mae: 0.0090 - val_loss: 2.3692e-04 - val_mae: 0.0101\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4881e-04 - mae: 0.0097 - val_loss: 1.9933e-04 - val_mae: 0.0087\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.5392e-04 - mae: 0.0096 - val_loss: 2.7810e-04 - val_mae: 0.0108\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0169e-04 - mae: 0.0082 - val_loss: 1.6293e-04 - val_mae: 0.0077\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.2579e-04 - mae: 0.0090 - val_loss: 1.8590e-04 - val_mae: 0.0090\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.2337e-04 - mae: 0.0087 - val_loss: 2.0398e-04 - val_mae: 0.0083\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.4283e-04 - mae: 0.0094 - val_loss: 2.5150e-04 - val_mae: 0.0107\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 2.2282e-04 - mae: 0.0089 - val_loss: 1.6090e-04 - val_mae: 0.0081\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0891e-04 - mae: 0.0085 - val_loss: 2.4520e-04 - val_mae: 0.0113\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.1429e-04 - mae: 0.0087 - val_loss: 2.3155e-04 - val_mae: 0.0088\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4097e-04 - mae: 0.0091 - val_loss: 1.5571e-04 - val_mae: 0.0071\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0934e-04 - mae: 0.0083 - val_loss: 1.9663e-04 - val_mae: 0.0084\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.2133e-04 - mae: 0.0089 - val_loss: 1.7747e-04 - val_mae: 0.0078\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.2587e-04 - mae: 0.0089 - val_loss: 2.9775e-04 - val_mae: 0.0102\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3226e-04 - mae: 0.0089 - val_loss: 2.2143e-04 - val_mae: 0.0086\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.2178e-04 - mae: 0.0089 - val_loss: 2.0282e-04 - val_mae: 0.0086\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 2.1450e-04 - mae: 0.0085 - val_loss: 2.6549e-04 - val_mae: 0.0106\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.3031e-04 - mae: 0.0090 - val_loss: 1.7874e-04 - val_mae: 0.0088\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0180e-04 - mae: 0.0083 - val_loss: 2.1047e-04 - val_mae: 0.0083\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.1996e-04 - mae: 0.0088 - val_loss: 1.5248e-04 - val_mae: 0.0077\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0242e-04 - mae: 0.0083 - val_loss: 1.4851e-04 - val_mae: 0.0071\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0219e-04 - mae: 0.0082 - val_loss: 2.0872e-04 - val_mae: 0.0088\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4048e-04 - mae: 0.0091 - val_loss: 1.9862e-04 - val_mae: 0.0083\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3088e-04 - mae: 0.0090 - val_loss: 2.2340e-04 - val_mae: 0.0087\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0695e-04 - mae: 0.0085 - val_loss: 2.1045e-04 - val_mae: 0.0092\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0973e-04 - mae: 0.0085 - val_loss: 1.5792e-04 - val_mae: 0.0077\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9063e-04 - mae: 0.0081 - val_loss: 1.4722e-04 - val_mae: 0.0075\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3236e-04 - mae: 0.0090 - val_loss: 2.0973e-04 - val_mae: 0.0087\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.3621e-04 - mae: 0.0090 - val_loss: 1.8660e-04 - val_mae: 0.0076\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.3771e-04 - mae: 0.0092 - val_loss: 1.9965e-04 - val_mae: 0.0092\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.0877e-04 - mae: 0.0086 - val_loss: 1.7056e-04 - val_mae: 0.0071\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.1653e-04 - mae: 0.0085 - val_loss: 2.7821e-04 - val_mae: 0.0117\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.2186e-04 - mae: 0.0090 - val_loss: 2.8872e-04 - val_mae: 0.0102\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.1511e-04 - mae: 0.0090 - val_loss: 2.0106e-04 - val_mae: 0.0089\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.2153e-04 - mae: 0.0089 - val_loss: 2.0695e-04 - val_mae: 0.0093\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.9850e-04 - mae: 0.0080 - val_loss: 2.4468e-04 - val_mae: 0.0103\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0691e-04 - mae: 0.0085 - val_loss: 1.9193e-04 - val_mae: 0.0089\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9931e-04 - mae: 0.0084 - val_loss: 1.6021e-04 - val_mae: 0.0084\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9452e-04 - mae: 0.0081 - val_loss: 1.6354e-04 - val_mae: 0.0074\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.1211e-04 - mae: 0.0085 - val_loss: 1.4003e-04 - val_mae: 0.0064\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.9101e-04 - mae: 0.0080 - val_loss: 1.4320e-04 - val_mae: 0.0068\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.1333e-04 - mae: 0.0087 - val_loss: 1.3357e-04 - val_mae: 0.0068\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.1475e-04 - mae: 0.0084 - val_loss: 2.7114e-04 - val_mae: 0.0125\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.1746e-04 - mae: 0.0090 - val_loss: 1.6081e-04 - val_mae: 0.0072\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.5484e-04 - mae: 0.0098 - val_loss: 1.5042e-04 - val_mae: 0.0074\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.9632e-04 - mae: 0.0083 - val_loss: 1.6556e-04 - val_mae: 0.0080\n",
      "Epoch 179/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4710e-04 - mae: 0.0093 - val_loss: 1.3492e-04 - val_mae: 0.0070\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.9773e-04 - mae: 0.0079 - val_loss: 1.6769e-04 - val_mae: 0.0082\n",
      "Epoch 181/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.8405e-04 - mae: 0.0079 - val_loss: 1.7522e-04 - val_mae: 0.0089\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9432e-04 - mae: 0.0082 - val_loss: 1.7449e-04 - val_mae: 0.0089\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.3775e-04 - mae: 0.0093 - val_loss: 3.1572e-04 - val_mae: 0.0100\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.4607e-04 - mae: 0.0090 - val_loss: 1.3820e-04 - val_mae: 0.0071\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 1.9654e-04 - mae: 0.0081 - val_loss: 1.7332e-04 - val_mae: 0.0092\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.8400e-04 - mae: 0.0078 - val_loss: 1.7069e-04 - val_mae: 0.0076\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 2.0928e-04 - mae: 0.0085 - val_loss: 1.5436e-04 - val_mae: 0.0079\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9319e-04 - mae: 0.0081 - val_loss: 1.5998e-04 - val_mae: 0.0077\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 1.9111e-04 - mae: 0.0081 - val_loss: 1.3768e-04 - val_mae: 0.0072\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0889e-04 - mae: 0.0085 - val_loss: 1.3494e-04 - val_mae: 0.0069\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 1.9753e-04 - mae: 0.0081 - val_loss: 1.9655e-04 - val_mae: 0.0090\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 2.0281e-04 - mae: 0.0086 - val_loss: 1.5197e-04 - val_mae: 0.0074\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 2.0430e-04 - mae: 0.0084 - val_loss: 2.1150e-04 - val_mae: 0.0094\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 1.8344e-04 - mae: 0.0082 - val_loss: 1.4634e-04 - val_mae: 0.0074\n",
      "Epoch 194: early stopping\n",
      "Loss: 0.00014633519458584487, MAE: 0.007368187885731459\n",
      "60/60 [==============================] - 0s 1ms/step\n",
      "R² score for output 1: 0.998367339950243\n",
      "R² score for output 2: 0.9980806887155446\n",
      "R² score for output 3: 0.9939910786255343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize the input data\n",
    "scaler = MinMaxScaler()\n",
    "scalery = MinMaxScaler()\n",
    "\n",
    "scaler = MaxAbsScaler()     # different scaler cause different results, MaxAbsScaler seems to work better\n",
    "scalery = MaxAbsScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scalery.fit_transform(y_train)\n",
    "y_test = scalery.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test,y_test), callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss}, MAE: {mae}\")\n",
    "\n",
    "# MaxAbsScaler Loss: 0.00014633519458584487, MAE: 0.007368187885731459\n",
    "\n",
    "# R2-score\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scalery.inverse_transform(y_pred)\n",
    "y_test = scalery.inverse_transform(y_test)\n",
    "r2_scores = [r2_score(y_test[:, i], y_pred[:, i]) for i in range(y_test.shape[1])]\n",
    "for i, r2 in enumerate(r2_scores):\n",
    "    print(f\"R² score for output {i+1}: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_69 (Dense)            (None, 256)               1024      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,947\n",
      "Trainable params: 44,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curve\n",
    "losses = pd.DataFrame(history.history)\n",
    "plt.plot(losses.index, losses['loss'], label='train_loss')\n",
    "plt.plot(losses.index, losses['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file\n",
    "model.save('clark-y-cnn-MaxAbsScaler.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
