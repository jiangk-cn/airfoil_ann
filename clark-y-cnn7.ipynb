{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: 根据已有数据创建神经网络ANN\n",
    "'''\n",
    "conda create -n myenv python=3.8\n",
    "conda activate myenv\n",
    "\n",
    "conda install numpy pandas scikit-learn\n",
    "conda install -c conda-forge tensorflow\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('clark-y-2.csv')\n",
    "\n",
    "# Filter the data\n",
    "filtered_df = df[\n",
    "    (df['Reynold'] >= 0.1e5) & (df['Reynold'] <= 40e5) &  # 雷诺数范围\n",
    "    (df['Mach'] >= 0.1) & (df['Mach'] <= 0.7) &            # 马赫数范围\n",
    "    (df['Alpha'] >= -3) & (df['Alpha'] <= 15)              # 迎角范围\n",
    "]\n",
    "\n",
    "# Split the data into inputs (X) and outputs (y)\n",
    "X = filtered_df[['Reynold', 'Mach', 'Alpha']].values\n",
    "y = filtered_df[['cl', 'cd', 'cm']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "125/125 [==============================] - 2s 8ms/step - loss: 1.0009 - mae: 0.7712 - val_loss: 0.8757 - val_mae: 0.7081\n",
      "Epoch 2/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.6706 - mae: 0.5941 - val_loss: 0.5703 - val_mae: 0.5031\n",
      "Epoch 3/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4675 - mae: 0.4445 - val_loss: 0.4357 - val_mae: 0.3955\n",
      "Epoch 4/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3688 - mae: 0.3659 - val_loss: 0.3554 - val_mae: 0.3438\n",
      "Epoch 5/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3000 - mae: 0.3158 - val_loss: 0.2852 - val_mae: 0.3052\n",
      "Epoch 6/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2343 - mae: 0.2763 - val_loss: 0.2200 - val_mae: 0.2689\n",
      "Epoch 7/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1796 - mae: 0.2454 - val_loss: 0.1697 - val_mae: 0.2461\n",
      "Epoch 8/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1420 - mae: 0.2256 - val_loss: 0.1368 - val_mae: 0.2251\n",
      "Epoch 9/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1198 - mae: 0.2140 - val_loss: 0.1220 - val_mae: 0.2222\n",
      "Epoch 10/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1043 - mae: 0.2032 - val_loss: 0.1090 - val_mae: 0.2136\n",
      "Epoch 11/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0948 - mae: 0.1972 - val_loss: 0.0970 - val_mae: 0.2024\n",
      "Epoch 12/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0868 - mae: 0.1913 - val_loss: 0.0903 - val_mae: 0.1973\n",
      "Epoch 13/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0807 - mae: 0.1859 - val_loss: 0.0846 - val_mae: 0.1922\n",
      "Epoch 14/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0758 - mae: 0.1803 - val_loss: 0.0790 - val_mae: 0.1834\n",
      "Epoch 15/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0710 - mae: 0.1742 - val_loss: 0.0742 - val_mae: 0.1784\n",
      "Epoch 16/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0661 - mae: 0.1674 - val_loss: 0.0688 - val_mae: 0.1695\n",
      "Epoch 17/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.0615 - mae: 0.1603 - val_loss: 0.0652 - val_mae: 0.1643\n",
      "Epoch 18/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0583 - mae: 0.1540 - val_loss: 0.0591 - val_mae: 0.1560\n",
      "Epoch 19/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0537 - mae: 0.1467 - val_loss: 0.0559 - val_mae: 0.1478\n",
      "Epoch 20/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0493 - mae: 0.1394 - val_loss: 0.0510 - val_mae: 0.1416\n",
      "Epoch 21/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0476 - mae: 0.1357 - val_loss: 0.0516 - val_mae: 0.1441\n",
      "Epoch 22/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0420 - mae: 0.1271 - val_loss: 0.0420 - val_mae: 0.1275\n",
      "Epoch 23/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1201 - val_loss: 0.0390 - val_mae: 0.1232\n",
      "Epoch 24/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1142 - val_loss: 0.0347 - val_mae: 0.1143\n",
      "Epoch 25/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1062 - val_loss: 0.0324 - val_mae: 0.1104\n",
      "Epoch 26/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0275 - mae: 0.0987 - val_loss: 0.0276 - val_mae: 0.1006\n",
      "Epoch 27/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0924 - val_loss: 0.0238 - val_mae: 0.0918\n",
      "Epoch 28/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0220 - mae: 0.0866 - val_loss: 0.0212 - val_mae: 0.0851\n",
      "Epoch 29/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.0812 - val_loss: 0.0195 - val_mae: 0.0825\n",
      "Epoch 30/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0183 - mae: 0.0789 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 31/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0739 - val_loss: 0.0153 - val_mae: 0.0725\n",
      "Epoch 32/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0742 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 33/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0689 - val_loss: 0.0130 - val_mae: 0.0675\n",
      "Epoch 34/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0124 - mae: 0.0659 - val_loss: 0.0119 - val_mae: 0.0648\n",
      "Epoch 35/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0628 - val_loss: 0.0107 - val_mae: 0.0615\n",
      "Epoch 36/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0603 - val_loss: 0.0101 - val_mae: 0.0610\n",
      "Epoch 37/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0095 - mae: 0.0593 - val_loss: 0.0091 - val_mae: 0.0576\n",
      "Epoch 38/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0578 - val_loss: 0.0086 - val_mae: 0.0574\n",
      "Epoch 39/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0085 - mae: 0.0570 - val_loss: 0.0086 - val_mae: 0.0582\n",
      "Epoch 40/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0570 - val_loss: 0.0080 - val_mae: 0.0560\n",
      "Epoch 41/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0075 - mae: 0.0544 - val_loss: 0.0080 - val_mae: 0.0563\n",
      "Epoch 42/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0525 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 43/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0538 - val_loss: 0.0080 - val_mae: 0.0572\n",
      "Epoch 44/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 0.0067 - val_mae: 0.0530\n",
      "Epoch 45/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0068 - mae: 0.0528 - val_loss: 0.0068 - val_mae: 0.0532\n",
      "Epoch 46/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0059 - mae: 0.0500 - val_loss: 0.0066 - val_mae: 0.0521\n",
      "Epoch 47/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0486 - val_loss: 0.0071 - val_mae: 0.0554\n",
      "Epoch 48/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0494 - val_loss: 0.0054 - val_mae: 0.0487\n",
      "Epoch 49/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0056 - mae: 0.0490 - val_loss: 0.0058 - val_mae: 0.0487\n",
      "Epoch 50/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0478 - val_loss: 0.0052 - val_mae: 0.0478\n",
      "Epoch 51/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0466 - val_loss: 0.0049 - val_mae: 0.0451\n",
      "Epoch 52/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.0047 - mae: 0.0448 - val_loss: 0.0050 - val_mae: 0.0461\n",
      "Epoch 53/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0047 - mae: 0.0452 - val_loss: 0.0055 - val_mae: 0.0492\n",
      "Epoch 54/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 0.0048 - val_mae: 0.0458\n",
      "Epoch 55/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0440 - val_loss: 0.0050 - val_mae: 0.0468\n",
      "Epoch 56/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0482 - val_loss: 0.0047 - val_mae: 0.0459\n",
      "Epoch 57/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0445 - val_loss: 0.0051 - val_mae: 0.0495\n",
      "Epoch 58/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0041 - mae: 0.0426 - val_loss: 0.0041 - val_mae: 0.0411\n",
      "Epoch 59/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0039 - mae: 0.0411 - val_loss: 0.0040 - val_mae: 0.0411\n",
      "Epoch 60/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0461 - val_loss: 0.0051 - val_mae: 0.0500\n",
      "Epoch 61/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0422 - val_loss: 0.0040 - val_mae: 0.0424\n",
      "Epoch 62/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0408 - val_loss: 0.0036 - val_mae: 0.0404\n",
      "Epoch 63/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0397 - val_loss: 0.0041 - val_mae: 0.0432\n",
      "Epoch 64/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0396 - val_loss: 0.0034 - val_mae: 0.0397\n",
      "Epoch 65/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0403 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 66/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0380 - val_loss: 0.0033 - val_mae: 0.0388\n",
      "Epoch 67/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0032 - mae: 0.0386 - val_loss: 0.0032 - val_mae: 0.0388\n",
      "Epoch 68/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0031 - mae: 0.0376 - val_loss: 0.0031 - val_mae: 0.0387\n",
      "Epoch 69/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0373 - val_loss: 0.0029 - val_mae: 0.0368\n",
      "Epoch 70/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0365 - val_loss: 0.0026 - val_mae: 0.0353\n",
      "Epoch 71/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0357 - val_loss: 0.0029 - val_mae: 0.0370\n",
      "Epoch 72/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0347 - val_loss: 0.0026 - val_mae: 0.0356\n",
      "Epoch 73/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.0025 - mae: 0.0341 - val_loss: 0.0023 - val_mae: 0.0333\n",
      "Epoch 74/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0332 - val_loss: 0.0024 - val_mae: 0.0344\n",
      "Epoch 75/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0353 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 76/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0368 - val_loss: 0.0026 - val_mae: 0.0358\n",
      "Epoch 77/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0329 - val_loss: 0.0030 - val_mae: 0.0393\n",
      "Epoch 78/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0332 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 79/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 80/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0019 - val_mae: 0.0301\n",
      "Epoch 81/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0021 - val_mae: 0.0315\n",
      "Epoch 82/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 83/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0022 - val_mae: 0.0336\n",
      "Epoch 84/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 85/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0021 - val_mae: 0.0328\n",
      "Epoch 86/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0026 - val_mae: 0.0345\n",
      "Epoch 87/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0019 - val_mae: 0.0306\n",
      "Epoch 88/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 89/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 90/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 91/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0285\n",
      "Epoch 92/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 93/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0015 - val_mae: 0.0259\n",
      "Epoch 94/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 95/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 0.0023 - val_mae: 0.0336\n",
      "Epoch 96/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0016 - val_mae: 0.0284\n",
      "Epoch 97/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0015 - val_mae: 0.0261\n",
      "Epoch 98/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 99/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 100/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 101/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 102/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 103/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0015 - val_mae: 0.0271\n",
      "Epoch 104/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 105/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 106/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0251\n",
      "Epoch 107/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 108/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 109/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 110/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0015 - val_mae: 0.0265\n",
      "Epoch 111/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0013 - val_mae: 0.0262\n",
      "Epoch 112/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 113/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 114/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 115/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 116/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 117/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 118/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 119/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 9.0994e-04 - val_mae: 0.0205\n",
      "Epoch 120/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 9.2543e-04 - val_mae: 0.0207\n",
      "Epoch 121/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 122/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 123/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0284\n",
      "Epoch 124/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 125/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 9.4480e-04 - val_mae: 0.0212\n",
      "Epoch 126/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.5763e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 127/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 128/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9237e-04 - mae: 0.0215 - val_loss: 8.2107e-04 - val_mae: 0.0194\n",
      "Epoch 129/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3820e-04 - mae: 0.0205 - val_loss: 9.8115e-04 - val_mae: 0.0226\n",
      "Epoch 130/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 9.6280e-04 - mae: 0.0212 - val_loss: 8.1576e-04 - val_mae: 0.0196\n",
      "Epoch 131/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 9.2795e-04 - mae: 0.0205 - val_loss: 9.0581e-04 - val_mae: 0.0207\n",
      "Epoch 132/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.6874e-04 - mae: 0.0213 - val_loss: 8.7453e-04 - val_mae: 0.0200\n",
      "Epoch 133/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 9.4073e-04 - val_mae: 0.0218\n",
      "Epoch 134/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 9.9963e-04 - mae: 0.0215 - val_loss: 7.8416e-04 - val_mae: 0.0187\n",
      "Epoch 135/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0248 - val_loss: 0.0021 - val_mae: 0.0293\n",
      "Epoch 136/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 137/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 138/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 9.0931e-04 - mae: 0.0205 - val_loss: 7.9672e-04 - val_mae: 0.0197\n",
      "Epoch 139/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 8.8361e-04 - mae: 0.0201 - val_loss: 8.8469e-04 - val_mae: 0.0208\n",
      "Epoch 140/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 8.5148e-04 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 141/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 8.5464e-04 - mae: 0.0198 - val_loss: 8.9476e-04 - val_mae: 0.0203\n",
      "Epoch 142/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.0773e-04 - mae: 0.0204 - val_loss: 8.8746e-04 - val_mae: 0.0204\n",
      "Epoch 143/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1278e-04 - mae: 0.0204 - val_loss: 9.3074e-04 - val_mae: 0.0205\n",
      "Epoch 144/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3296e-04 - mae: 0.0196 - val_loss: 8.9457e-04 - val_mae: 0.0215\n",
      "Epoch 145/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 7.7608e-04 - mae: 0.0188 - val_loss: 7.9247e-04 - val_mae: 0.0192\n",
      "Epoch 146/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.0826e-04 - mae: 0.0192 - val_loss: 8.4060e-04 - val_mae: 0.0202\n",
      "Epoch 147/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.3233e-04 - mae: 0.0206 - val_loss: 9.3115e-04 - val_mae: 0.0211\n",
      "Epoch 148/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.7984e-04 - mae: 0.0200 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 149/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0295 - val_loss: 0.0021 - val_mae: 0.0326\n",
      "Epoch 150/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 8.7555e-04 - val_mae: 0.0214\n",
      "Epoch 151/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5740e-04 - mae: 0.0208 - val_loss: 0.0013 - val_mae: 0.0229\n",
      "Epoch 152/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 9.3866e-04 - mae: 0.0207 - val_loss: 6.7231e-04 - val_mae: 0.0178\n",
      "Epoch 153/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.3530e-04 - mae: 0.0190 - val_loss: 7.2331e-04 - val_mae: 0.0184\n",
      "Epoch 154/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9513e-04 - mae: 0.0210 - val_loss: 8.0794e-04 - val_mae: 0.0200\n",
      "Epoch 155/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0394 - val_loss: 0.0044 - val_mae: 0.0467\n",
      "Epoch 156/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0300 - val_loss: 7.4437e-04 - val_mae: 0.0185\n",
      "Epoch 157/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.6949e-04 - mae: 0.0182 - val_loss: 6.7189e-04 - val_mae: 0.0178\n",
      "Epoch 158/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.0415e-04 - mae: 0.0176 - val_loss: 6.6921e-04 - val_mae: 0.0176\n",
      "Epoch 159/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.0624e-04 - mae: 0.0176 - val_loss: 6.6867e-04 - val_mae: 0.0180\n",
      "Epoch 160/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 6.5825e-04 - mae: 0.0169 - val_loss: 6.5032e-04 - val_mae: 0.0169\n",
      "Epoch 161/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.4546e-04 - mae: 0.0168 - val_loss: 6.4906e-04 - val_mae: 0.0175\n",
      "Epoch 162/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4762e-04 - mae: 0.0168 - val_loss: 6.6646e-04 - val_mae: 0.0173\n",
      "Epoch 163/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 6.5567e-04 - mae: 0.0170 - val_loss: 6.5086e-04 - val_mae: 0.0170\n",
      "Epoch 164/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.7788e-04 - mae: 0.0173 - val_loss: 6.2510e-04 - val_mae: 0.0166\n",
      "Epoch 165/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.3848e-04 - mae: 0.0167 - val_loss: 6.7423e-04 - val_mae: 0.0179\n",
      "Epoch 166/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.5028e-04 - mae: 0.0169 - val_loss: 5.8767e-04 - val_mae: 0.0164\n",
      "Epoch 167/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 6.5002e-04 - mae: 0.0170 - val_loss: 5.6181e-04 - val_mae: 0.0163\n",
      "Epoch 168/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.7155e-04 - mae: 0.0176 - val_loss: 6.1105e-04 - val_mae: 0.0167\n",
      "Epoch 169/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1624e-04 - mae: 0.0165 - val_loss: 6.2468e-04 - val_mae: 0.0172\n",
      "Epoch 170/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.1559e-04 - mae: 0.0165 - val_loss: 6.3385e-04 - val_mae: 0.0177\n",
      "Epoch 171/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.5412e-04 - mae: 0.0172 - val_loss: 6.8878e-04 - val_mae: 0.0180\n",
      "Epoch 172/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.8224e-04 - mae: 0.0174 - val_loss: 6.4830e-04 - val_mae: 0.0173\n",
      "Epoch 173/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.7374e-04 - mae: 0.0175 - val_loss: 6.2271e-04 - val_mae: 0.0172\n",
      "Epoch 174/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4902e-04 - mae: 0.0170 - val_loss: 5.7135e-04 - val_mae: 0.0165\n",
      "Epoch 175/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 6.5026e-04 - mae: 0.0168 - val_loss: 5.9146e-04 - val_mae: 0.0164\n",
      "Epoch 176/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.7097e-04 - mae: 0.0172 - val_loss: 6.0406e-04 - val_mae: 0.0167\n",
      "Epoch 177/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.3507e-04 - mae: 0.0169 - val_loss: 5.3586e-04 - val_mae: 0.0153\n",
      "Epoch 178/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.2860e-04 - mae: 0.0164 - val_loss: 6.6394e-04 - val_mae: 0.0173\n",
      "Epoch 179/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5957e-04 - mae: 0.0194 - val_loss: 6.6048e-04 - val_mae: 0.0176\n",
      "Epoch 180/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.7164e-04 - mae: 0.0174 - val_loss: 6.4776e-04 - val_mae: 0.0173\n",
      "Epoch 181/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.6280e-04 - mae: 0.0175 - val_loss: 6.1459e-04 - val_mae: 0.0168\n",
      "Epoch 182/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 9.3979e-04 - mae: 0.0203 - val_loss: 6.0121e-04 - val_mae: 0.0165\n",
      "Epoch 183/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 6.5500e-04 - mae: 0.0170 - val_loss: 6.1718e-04 - val_mae: 0.0176\n",
      "Epoch 184/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4310e-04 - mae: 0.0169 - val_loss: 4.9314e-04 - val_mae: 0.0151\n",
      "Epoch 185/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.6955e-04 - mae: 0.0158 - val_loss: 6.7000e-04 - val_mae: 0.0179\n",
      "Epoch 186/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.8510e-04 - mae: 0.0161 - val_loss: 6.9421e-04 - val_mae: 0.0171\n",
      "Epoch 187/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.5680e-04 - mae: 0.0185 - val_loss: 6.7978e-04 - val_mae: 0.0180\n",
      "Epoch 188/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.8447e-04 - mae: 0.0160 - val_loss: 5.4899e-04 - val_mae: 0.0158\n",
      "Epoch 189/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 8.4185e-04 - mae: 0.0189 - val_loss: 0.0016 - val_mae: 0.0249\n",
      "Epoch 190/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.3788e-04 - mae: 0.0192 - val_loss: 6.2283e-04 - val_mae: 0.0165\n",
      "Epoch 191/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 9.0117e-04 - mae: 0.0192 - val_loss: 0.0014 - val_mae: 0.0237\n",
      "Epoch 192/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0241 - val_loss: 6.7054e-04 - val_mae: 0.0169\n",
      "Epoch 193/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.6017e-04 - mae: 0.0158 - val_loss: 5.2216e-04 - val_mae: 0.0153\n",
      "Epoch 194/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.4933e-04 - mae: 0.0154 - val_loss: 6.2018e-04 - val_mae: 0.0177\n",
      "Epoch 195/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.4672e-04 - mae: 0.0153 - val_loss: 6.3806e-04 - val_mae: 0.0172\n",
      "Epoch 196/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 5.6129e-04 - mae: 0.0157 - val_loss: 5.8486e-04 - val_mae: 0.0158\n",
      "Epoch 197/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.9073e-04 - mae: 0.0160 - val_loss: 4.8656e-04 - val_mae: 0.0150\n",
      "Epoch 198/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.4439e-04 - mae: 0.0177 - val_loss: 8.5665e-04 - val_mae: 0.0204\n",
      "Epoch 199/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.6851e-04 - mae: 0.0182 - val_loss: 5.6390e-04 - val_mae: 0.0162\n",
      "Epoch 200/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.3560e-04 - mae: 0.0153 - val_loss: 7.2402e-04 - val_mae: 0.0179\n",
      "Epoch 201/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.8353e-04 - mae: 0.0194 - val_loss: 5.0827e-04 - val_mae: 0.0150\n",
      "Epoch 202/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1704e-04 - mae: 0.0167 - val_loss: 5.8141e-04 - val_mae: 0.0169\n",
      "Epoch 203/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.5821e-04 - mae: 0.0156 - val_loss: 6.0595e-04 - val_mae: 0.0161\n",
      "Epoch 204/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 6.0113e-04 - mae: 0.0162 - val_loss: 4.7678e-04 - val_mae: 0.0144\n",
      "Epoch 205/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6508e-04 - mae: 0.0156 - val_loss: 5.7052e-04 - val_mae: 0.0161\n",
      "Epoch 206/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4345e-04 - mae: 0.0167 - val_loss: 6.9090e-04 - val_mae: 0.0174\n",
      "Epoch 207/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.3567e-04 - mae: 0.0153 - val_loss: 5.0284e-04 - val_mae: 0.0148\n",
      "Epoch 208/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.1853e-04 - mae: 0.0149 - val_loss: 5.0805e-04 - val_mae: 0.0144\n",
      "Epoch 209/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6185e-04 - mae: 0.0156 - val_loss: 7.5498e-04 - val_mae: 0.0187\n",
      "Epoch 210/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.8765e-04 - mae: 0.0157 - val_loss: 5.1670e-04 - val_mae: 0.0149\n",
      "Epoch 211/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.2862e-04 - mae: 0.0151 - val_loss: 4.6528e-04 - val_mae: 0.0145\n",
      "Epoch 212/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.6290e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 213/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.3107e-04 - mae: 0.0159 - val_loss: 0.0034 - val_mae: 0.0297\n",
      "Epoch 214/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0217 - val_loss: 5.1147e-04 - val_mae: 0.0144\n",
      "Epoch 215/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.3884e-04 - mae: 0.0149 - val_loss: 5.3323e-04 - val_mae: 0.0153\n",
      "Epoch 216/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.6590e-04 - mae: 0.0154 - val_loss: 7.2881e-04 - val_mae: 0.0189\n",
      "Epoch 217/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.8733e-04 - mae: 0.0165 - val_loss: 5.8735e-04 - val_mae: 0.0164\n",
      "Epoch 218/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.5381e-04 - mae: 0.0139 - val_loss: 4.4907e-04 - val_mae: 0.0140\n",
      "Epoch 219/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 9.1702e-04 - mae: 0.0190 - val_loss: 4.9148e-04 - val_mae: 0.0147\n",
      "Epoch 220/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 5.5832e-04 - mae: 0.0154 - val_loss: 5.1744e-04 - val_mae: 0.0159\n",
      "Epoch 221/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5066e-04 - mae: 0.0137 - val_loss: 4.5395e-04 - val_mae: 0.0141\n",
      "Epoch 222/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.2617e-04 - mae: 0.0147 - val_loss: 0.0011 - val_mae: 0.0189\n",
      "Epoch 223/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0224 - val_loss: 0.0010 - val_mae: 0.0233\n",
      "Epoch 224/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.6434e-04 - mae: 0.0167 - val_loss: 4.8482e-04 - val_mae: 0.0147\n",
      "Epoch 225/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.4886e-04 - mae: 0.0140 - val_loss: 4.6562e-04 - val_mae: 0.0143\n",
      "Epoch 226/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7517e-04 - mae: 0.0144 - val_loss: 4.4069e-04 - val_mae: 0.0134\n",
      "Epoch 227/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.6429e-04 - mae: 0.0154 - val_loss: 5.4091e-04 - val_mae: 0.0157\n",
      "Epoch 228/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.4223e-04 - mae: 0.0135 - val_loss: 4.9113e-04 - val_mae: 0.0140\n",
      "Epoch 229/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7931e-04 - mae: 0.0145 - val_loss: 4.4188e-04 - val_mae: 0.0136\n",
      "Epoch 230/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.8194e-04 - mae: 0.0145 - val_loss: 5.4915e-04 - val_mae: 0.0163\n",
      "Epoch 231/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.6957e-04 - mae: 0.0142 - val_loss: 4.8708e-04 - val_mae: 0.0141\n",
      "Epoch 232/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0012 - mae: 0.0215 - val_loss: 4.9162e-04 - val_mae: 0.0148\n",
      "Epoch 233/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.9630e-04 - mae: 0.0160 - val_loss: 5.2876e-04 - val_mae: 0.0148\n",
      "Epoch 234/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.3219e-04 - mae: 0.0150 - val_loss: 5.7758e-04 - val_mae: 0.0164\n",
      "Epoch 235/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.9616e-04 - mae: 0.0144 - val_loss: 6.1769e-04 - val_mae: 0.0171\n",
      "Epoch 236/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5846e-04 - mae: 0.0155 - val_loss: 4.2811e-04 - val_mae: 0.0129\n",
      "Epoch 237/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4377e-04 - mae: 0.0134 - val_loss: 0.0011 - val_mae: 0.0202\n",
      "Epoch 238/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.0035e-04 - mae: 0.0145 - val_loss: 4.7185e-04 - val_mae: 0.0145\n",
      "Epoch 239/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.9658e-04 - mae: 0.0144 - val_loss: 4.7016e-04 - val_mae: 0.0142\n",
      "Epoch 240/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7342e-04 - mae: 0.0142 - val_loss: 6.3930e-04 - val_mae: 0.0154\n",
      "Epoch 241/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.3810e-04 - mae: 0.0166 - val_loss: 4.2478e-04 - val_mae: 0.0140\n",
      "Epoch 242/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.3214e-04 - mae: 0.0176 - val_loss: 9.1069e-04 - val_mae: 0.0198\n",
      "Epoch 243/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 5.8535e-04 - mae: 0.0159 - val_loss: 5.9649e-04 - val_mae: 0.0162\n",
      "Epoch 244/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.9531e-04 - mae: 0.0144 - val_loss: 4.9000e-04 - val_mae: 0.0154\n",
      "Epoch 245/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6068e-04 - mae: 0.0140 - val_loss: 4.3892e-04 - val_mae: 0.0138\n",
      "Epoch 246/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5414e-04 - mae: 0.0148 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 247/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 5.5874e-04 - mae: 0.0158 - val_loss: 3.9422e-04 - val_mae: 0.0129\n",
      "Epoch 248/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6029e-04 - mae: 0.0148 - val_loss: 5.9543e-04 - val_mae: 0.0179\n",
      "Epoch 249/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6984e-04 - mae: 0.0143 - val_loss: 6.2583e-04 - val_mae: 0.0165\n",
      "Epoch 250/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.2487e-04 - mae: 0.0151 - val_loss: 3.9714e-04 - val_mae: 0.0132\n",
      "Epoch 251/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1336e-04 - mae: 0.0145 - val_loss: 3.8399e-04 - val_mae: 0.0123\n",
      "Epoch 252/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.3170e-04 - mae: 0.0133 - val_loss: 5.3754e-04 - val_mae: 0.0149\n",
      "Epoch 253/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 5.5196e-04 - mae: 0.0153 - val_loss: 0.0015 - val_mae: 0.0197\n",
      "Epoch 254/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.4618e-04 - mae: 0.0173 - val_loss: 6.1735e-04 - val_mae: 0.0167\n",
      "Epoch 255/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.1206e-04 - mae: 0.0144 - val_loss: 0.0049 - val_mae: 0.0364\n",
      "Epoch 256/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 9.4835e-04 - mae: 0.0186 - val_loss: 5.5738e-04 - val_mae: 0.0156\n",
      "Epoch 257/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.0729e-04 - mae: 0.0144 - val_loss: 3.7329e-04 - val_mae: 0.0119\n",
      "Epoch 258/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.5071e-04 - mae: 0.0137 - val_loss: 3.5481e-04 - val_mae: 0.0118\n",
      "Epoch 259/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2432e-04 - mae: 0.0134 - val_loss: 5.0472e-04 - val_mae: 0.0151\n",
      "Epoch 260/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.6889e-04 - mae: 0.0142 - val_loss: 3.8000e-04 - val_mae: 0.0129\n",
      "Epoch 261/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.7080e-04 - mae: 0.0126 - val_loss: 3.7539e-04 - val_mae: 0.0131\n",
      "Epoch 262/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.6109e-04 - mae: 0.0151 - val_loss: 6.4208e-04 - val_mae: 0.0156\n",
      "Epoch 263/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.7840e-04 - mae: 0.0142 - val_loss: 3.8621e-04 - val_mae: 0.0126\n",
      "Epoch 264/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.8363e-04 - mae: 0.0125 - val_loss: 4.0601e-04 - val_mae: 0.0133\n",
      "Epoch 265/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2892e-04 - mae: 0.0133 - val_loss: 4.8966e-04 - val_mae: 0.0144\n",
      "Epoch 266/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2108e-04 - mae: 0.0134 - val_loss: 3.5860e-04 - val_mae: 0.0120\n",
      "Epoch 267/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.3798e-04 - mae: 0.0133 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 268/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 5.6897e-04 - mae: 0.0156 - val_loss: 4.0306e-04 - val_mae: 0.0128\n",
      "Epoch 269/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2191e-04 - mae: 0.0133 - val_loss: 4.8558e-04 - val_mae: 0.0141\n",
      "Epoch 270/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2390e-04 - mae: 0.0132 - val_loss: 3.9626e-04 - val_mae: 0.0126\n",
      "Epoch 271/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.4669e-04 - mae: 0.0136 - val_loss: 4.2328e-04 - val_mae: 0.0130\n",
      "Epoch 272/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.6075e-04 - mae: 0.0141 - val_loss: 3.9259e-04 - val_mae: 0.0125\n",
      "Epoch 273/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.4679e-04 - mae: 0.0139 - val_loss: 4.2544e-04 - val_mae: 0.0140\n",
      "Epoch 274/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.9949e-04 - mae: 0.0155 - val_loss: 9.5026e-04 - val_mae: 0.0202\n",
      "Epoch 275/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.8965e-04 - mae: 0.0152 - val_loss: 3.7381e-04 - val_mae: 0.0126\n",
      "Epoch 276/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8033e-04 - mae: 0.0126 - val_loss: 4.0108e-04 - val_mae: 0.0130\n",
      "Epoch 277/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0823e-04 - mae: 0.0131 - val_loss: 6.2082e-04 - val_mae: 0.0158\n",
      "Epoch 278/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7529e-04 - mae: 0.0139 - val_loss: 5.7593e-04 - val_mae: 0.0156\n",
      "Epoch 279/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2640e-04 - mae: 0.0137 - val_loss: 3.3278e-04 - val_mae: 0.0119\n",
      "Epoch 280/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.3071e-04 - mae: 0.0136 - val_loss: 5.7044e-04 - val_mae: 0.0143\n",
      "Epoch 281/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1283e-04 - mae: 0.0162 - val_loss: 3.5400e-04 - val_mae: 0.0126\n",
      "Epoch 282/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 4.7081e-04 - mae: 0.0138 - val_loss: 4.8534e-04 - val_mae: 0.0150\n",
      "Epoch 283/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.5126e-04 - mae: 0.0137 - val_loss: 4.8703e-04 - val_mae: 0.0146\n",
      "Epoch 284/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.0484e-04 - mae: 0.0131 - val_loss: 3.8260e-04 - val_mae: 0.0126\n",
      "Epoch 285/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.0222e-04 - mae: 0.0136 - val_loss: 0.0018 - val_mae: 0.0266\n",
      "Epoch 286/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1616e-04 - mae: 0.0173 - val_loss: 4.9413e-04 - val_mae: 0.0138\n",
      "Epoch 287/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.9689e-04 - mae: 0.0141 - val_loss: 5.7332e-04 - val_mae: 0.0163\n",
      "Epoch 288/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.6837e-04 - mae: 0.0136 - val_loss: 4.3916e-04 - val_mae: 0.0135\n",
      "Epoch 289/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.7055e-04 - mae: 0.0124 - val_loss: 4.4708e-04 - val_mae: 0.0137\n",
      "Epoch 290/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1148e-04 - mae: 0.0130 - val_loss: 3.4852e-04 - val_mae: 0.0123\n",
      "Epoch 291/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 6.5240e-04 - val_mae: 0.0184\n",
      "Epoch 292/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.4949e-04 - mae: 0.0136 - val_loss: 3.8674e-04 - val_mae: 0.0130\n",
      "Epoch 293/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.2359e-04 - mae: 0.0143 - val_loss: 4.7775e-04 - val_mae: 0.0137\n",
      "Epoch 294/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.5592e-04 - mae: 0.0122 - val_loss: 3.3584e-04 - val_mae: 0.0122\n",
      "Epoch 295/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.8079e-04 - mae: 0.0125 - val_loss: 3.6409e-04 - val_mae: 0.0122\n",
      "Epoch 296/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.4139e-04 - mae: 0.0119 - val_loss: 3.6241e-04 - val_mae: 0.0124\n",
      "Epoch 297/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.5577e-04 - mae: 0.0139 - val_loss: 8.1444e-04 - val_mae: 0.0167\n",
      "Epoch 298/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.4289e-04 - mae: 0.0131 - val_loss: 3.9020e-04 - val_mae: 0.0131\n",
      "Epoch 299/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.6852e-04 - mae: 0.0123 - val_loss: 4.1359e-04 - val_mae: 0.0128\n",
      "Epoch 300/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.4943e-04 - mae: 0.0136 - val_loss: 4.5938e-04 - val_mae: 0.0127\n",
      "Epoch 301/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.8405e-04 - mae: 0.0154 - val_loss: 0.0068 - val_mae: 0.0527\n",
      "Epoch 302/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0237 - val_loss: 5.1641e-04 - val_mae: 0.0140\n",
      "Epoch 303/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.2706e-04 - mae: 0.0115 - val_loss: 3.1889e-04 - val_mae: 0.0110\n",
      "Epoch 304/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5385e-04 - mae: 0.0142 - val_loss: 4.8399e-04 - val_mae: 0.0153\n",
      "Epoch 305/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.8062e-04 - mae: 0.0137 - val_loss: 3.2955e-04 - val_mae: 0.0114\n",
      "Epoch 306/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5096e-04 - mae: 0.0119 - val_loss: 3.2344e-04 - val_mae: 0.0114\n",
      "Epoch 307/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.0485e-04 - mae: 0.0111 - val_loss: 3.0868e-04 - val_mae: 0.0107\n",
      "Epoch 308/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.5835e-04 - mae: 0.0119 - val_loss: 4.3509e-04 - val_mae: 0.0135\n",
      "Epoch 309/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.4267e-04 - mae: 0.0118 - val_loss: 3.1696e-04 - val_mae: 0.0111\n",
      "Epoch 310/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6460e-04 - mae: 0.0121 - val_loss: 3.3726e-04 - val_mae: 0.0116\n",
      "Epoch 311/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0402e-04 - mae: 0.0128 - val_loss: 3.6732e-04 - val_mae: 0.0130\n",
      "Epoch 312/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5313e-04 - mae: 0.0120 - val_loss: 4.1020e-04 - val_mae: 0.0132\n",
      "Epoch 313/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 4.8336e-04 - mae: 0.0140 - val_loss: 3.2220e-04 - val_mae: 0.0111\n",
      "Epoch 314/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 3.3403e-04 - mae: 0.0116 - val_loss: 2.9718e-04 - val_mae: 0.0108\n",
      "Epoch 315/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.2734e-04 - mae: 0.0117 - val_loss: 3.3901e-04 - val_mae: 0.0119\n",
      "Epoch 316/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 3.6437e-04 - mae: 0.0119 - val_loss: 6.5876e-04 - val_mae: 0.0187\n",
      "Epoch 317/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.4438e-04 - mae: 0.0119 - val_loss: 3.5765e-04 - val_mae: 0.0118\n",
      "Epoch 318/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.4169e-04 - mae: 0.0133 - val_loss: 0.0020 - val_mae: 0.0218\n",
      "Epoch 319/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1750e-04 - mae: 0.0146 - val_loss: 3.5359e-04 - val_mae: 0.0124\n",
      "Epoch 320/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2768e-04 - mae: 0.0130 - val_loss: 5.5294e-04 - val_mae: 0.0148\n",
      "Epoch 321/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 7.2078e-04 - mae: 0.0167 - val_loss: 3.5226e-04 - val_mae: 0.0130\n",
      "Epoch 322/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8808e-04 - mae: 0.0125 - val_loss: 3.3029e-04 - val_mae: 0.0118\n",
      "Epoch 323/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.5902e-04 - mae: 0.0120 - val_loss: 4.0795e-04 - val_mae: 0.0131\n",
      "Epoch 324/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5685e-04 - mae: 0.0135 - val_loss: 5.0808e-04 - val_mae: 0.0145\n",
      "Epoch 325/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6380e-04 - mae: 0.0121 - val_loss: 3.4392e-04 - val_mae: 0.0113\n",
      "Epoch 326/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.2142e-04 - mae: 0.0116 - val_loss: 3.9094e-04 - val_mae: 0.0122\n",
      "Epoch 327/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2175e-04 - mae: 0.0128 - val_loss: 0.0016 - val_mae: 0.0250\n",
      "Epoch 328/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.9015e-04 - mae: 0.0143 - val_loss: 4.4857e-04 - val_mae: 0.0129\n",
      "Epoch 329/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2053e-04 - mae: 0.0142 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 330/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 7.4507e-04 - mae: 0.0174 - val_loss: 3.3067e-04 - val_mae: 0.0123\n",
      "Epoch 331/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.9777e-04 - mae: 0.0110 - val_loss: 4.2039e-04 - val_mae: 0.0125\n",
      "Epoch 332/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.0971e-04 - mae: 0.0112 - val_loss: 2.9024e-04 - val_mae: 0.0110\n",
      "Epoch 333/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9718e-04 - mae: 0.0109 - val_loss: 3.9054e-04 - val_mae: 0.0131\n",
      "Epoch 334/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.0188e-04 - mae: 0.0153 - val_loss: 4.7899e-04 - val_mae: 0.0155\n",
      "Epoch 335/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0304 - val_loss: 0.0017 - val_mae: 0.0269\n",
      "Epoch 336/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.2833e-04 - mae: 0.0143 - val_loss: 3.4564e-04 - val_mae: 0.0111\n",
      "Epoch 337/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8269e-04 - mae: 0.0104 - val_loss: 3.3774e-04 - val_mae: 0.0113\n",
      "Epoch 338/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.8107e-04 - mae: 0.0103 - val_loss: 3.1403e-04 - val_mae: 0.0116\n",
      "Epoch 339/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8478e-04 - mae: 0.0106 - val_loss: 3.3355e-04 - val_mae: 0.0110\n",
      "Epoch 340/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8641e-04 - mae: 0.0107 - val_loss: 3.2325e-04 - val_mae: 0.0118\n",
      "Epoch 341/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 2.6407e-04 - mae: 0.0102 - val_loss: 2.9996e-04 - val_mae: 0.0103\n",
      "Epoch 342/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9373e-04 - mae: 0.0109 - val_loss: 4.5310e-04 - val_mae: 0.0137\n",
      "Epoch 343/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.1135e-04 - mae: 0.0110 - val_loss: 4.7184e-04 - val_mae: 0.0144\n",
      "Epoch 344/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.1228e-04 - mae: 0.0110 - val_loss: 4.0134e-04 - val_mae: 0.0135\n",
      "Epoch 345/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8219e-04 - mae: 0.0106 - val_loss: 3.1530e-04 - val_mae: 0.0115\n",
      "Epoch 346/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9406e-04 - mae: 0.0109 - val_loss: 3.1631e-04 - val_mae: 0.0115\n",
      "Epoch 347/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.0883e-04 - mae: 0.0112 - val_loss: 2.7245e-04 - val_mae: 0.0103\n",
      "Epoch 348/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.1527e-04 - mae: 0.0114 - val_loss: 3.9029e-04 - val_mae: 0.0134\n",
      "Epoch 349/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 3.0209e-04 - mae: 0.0112 - val_loss: 2.9315e-04 - val_mae: 0.0112\n",
      "Epoch 350/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.7295e-04 - mae: 0.0104 - val_loss: 4.9897e-04 - val_mae: 0.0139\n",
      "Epoch 351/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.8179e-04 - mae: 0.0125 - val_loss: 4.8889e-04 - val_mae: 0.0144\n",
      "Epoch 352/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2161e-04 - mae: 0.0113 - val_loss: 5.2305e-04 - val_mae: 0.0146\n",
      "Epoch 353/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 3.9825e-04 - mae: 0.0130 - val_loss: 4.4585e-04 - val_mae: 0.0122\n",
      "Epoch 354/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.7085e-04 - mae: 0.0125 - val_loss: 2.7900e-04 - val_mae: 0.0110\n",
      "Epoch 355/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.2150e-04 - mae: 0.0114 - val_loss: 4.5923e-04 - val_mae: 0.0140\n",
      "Epoch 356/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4781e-04 - mae: 0.0120 - val_loss: 4.0285e-04 - val_mae: 0.0129\n",
      "Epoch 357/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.4121e-04 - mae: 0.0151 - val_loss: 6.5905e-04 - val_mae: 0.0170\n",
      "Epoch 358/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8519e-04 - mae: 0.0129 - val_loss: 4.2723e-04 - val_mae: 0.0146\n",
      "Epoch 359/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.3925e-04 - mae: 0.0116 - val_loss: 4.0853e-04 - val_mae: 0.0145\n",
      "Epoch 360/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 4.5427e-04 - mae: 0.0138 - val_loss: 2.8788e-04 - val_mae: 0.0105\n",
      "Epoch 361/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5545e-04 - mae: 0.0119 - val_loss: 3.4544e-04 - val_mae: 0.0115\n",
      "Epoch 362/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.9753e-04 - mae: 0.0124 - val_loss: 3.4181e-04 - val_mae: 0.0121\n",
      "Epoch 363/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.9740e-04 - mae: 0.0125 - val_loss: 3.4689e-04 - val_mae: 0.0115\n",
      "Epoch 364/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6366e-04 - mae: 0.0124 - val_loss: 3.2657e-04 - val_mae: 0.0111\n",
      "Epoch 365/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.7953e-04 - mae: 0.0123 - val_loss: 6.6148e-04 - val_mae: 0.0154\n",
      "Epoch 366/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.1921e-04 - mae: 0.0132 - val_loss: 3.2915e-04 - val_mae: 0.0124\n",
      "Epoch 367/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 3.0305e-04 - mae: 0.0112 - val_loss: 3.8368e-04 - val_mae: 0.0121\n",
      "Epoch 368/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5501e-04 - mae: 0.0120 - val_loss: 4.1840e-04 - val_mae: 0.0134\n",
      "Epoch 369/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.7838e-04 - mae: 0.0146 - val_loss: 0.0024 - val_mae: 0.0323\n",
      "Epoch 370/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 8.9711e-04 - mae: 0.0193 - val_loss: 3.8051e-04 - val_mae: 0.0134\n",
      "Epoch 371/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.9234e-04 - mae: 0.0125 - val_loss: 3.0487e-04 - val_mae: 0.0111\n",
      "Epoch 372/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9109e-04 - mae: 0.0107 - val_loss: 2.7200e-04 - val_mae: 0.0106\n",
      "Epoch 373/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5396e-04 - mae: 0.0119 - val_loss: 4.3745e-04 - val_mae: 0.0127\n",
      "Epoch 374/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.6659e-04 - mae: 0.0123 - val_loss: 3.8744e-04 - val_mae: 0.0121\n",
      "Epoch 375/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.5313e-04 - mae: 0.0116 - val_loss: 2.6979e-04 - val_mae: 0.0102\n",
      "Epoch 376/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.1230e-04 - mae: 0.0112 - val_loss: 3.0779e-04 - val_mae: 0.0121\n",
      "Epoch 377/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6469e-04 - mae: 0.0123 - val_loss: 4.1189e-04 - val_mae: 0.0134\n",
      "Epoch 378/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.0289e-04 - mae: 0.0111 - val_loss: 4.4410e-04 - val_mae: 0.0128\n",
      "Epoch 379/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.8889e-04 - mae: 0.0143 - val_loss: 3.8317e-04 - val_mae: 0.0132\n",
      "Epoch 380/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.7047e-04 - mae: 0.0140 - val_loss: 3.2951e-04 - val_mae: 0.0105\n",
      "Epoch 381/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.2472e-04 - mae: 0.0114 - val_loss: 4.3431e-04 - val_mae: 0.0134\n",
      "Epoch 382/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.0671e-04 - mae: 0.0111 - val_loss: 2.9235e-04 - val_mae: 0.0109\n",
      "Epoch 383/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4304e-04 - mae: 0.0119 - val_loss: 3.2034e-04 - val_mae: 0.0114\n",
      "Epoch 384/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2397e-04 - mae: 0.0131 - val_loss: 5.8655e-04 - val_mae: 0.0167\n",
      "Epoch 385/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5240e-04 - mae: 0.0121 - val_loss: 2.7021e-04 - val_mae: 0.0099\n",
      "Epoch 386/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7336e-04 - mae: 0.0138 - val_loss: 2.8588e-04 - val_mae: 0.0107\n",
      "Epoch 387/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7403e-04 - mae: 0.0125 - val_loss: 3.0496e-04 - val_mae: 0.0108\n",
      "Epoch 388/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.8743e-04 - mae: 0.0107 - val_loss: 4.6872e-04 - val_mae: 0.0155\n",
      "Epoch 389/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1328e-04 - mae: 0.0131 - val_loss: 2.8766e-04 - val_mae: 0.0105\n",
      "Epoch 390/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.2578e-04 - mae: 0.0155 - val_loss: 7.8599e-04 - val_mae: 0.0168\n",
      "Epoch 391/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.7615e-04 - mae: 0.0141 - val_loss: 3.6578e-04 - val_mae: 0.0112\n",
      "Epoch 392/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 4.5737e-04 - mae: 0.0137 - val_loss: 3.0960e-04 - val_mae: 0.0110\n",
      "Epoch 393/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9616e-04 - mae: 0.0112 - val_loss: 2.5243e-04 - val_mae: 0.0101\n",
      "Epoch 394/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9378e-04 - mae: 0.0109 - val_loss: 3.1948e-04 - val_mae: 0.0108\n",
      "Epoch 395/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6237e-04 - mae: 0.0115 - val_loss: 7.0043e-04 - val_mae: 0.0177\n",
      "Epoch 396/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 3.1143e-04 - mae: 0.0113 - val_loss: 2.9115e-04 - val_mae: 0.0110\n",
      "Epoch 397/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.9915e-04 - mae: 0.0123 - val_loss: 4.7960e-04 - val_mae: 0.0143\n",
      "Epoch 398/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.4472e-04 - mae: 0.0115 - val_loss: 6.5571e-04 - val_mae: 0.0160\n",
      "Epoch 399/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4459e-04 - mae: 0.0130 - val_loss: 5.3199e-04 - val_mae: 0.0150\n",
      "Epoch 400/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 4.8423e-04 - mae: 0.0142 - val_loss: 2.4209e-04 - val_mae: 0.0095\n",
      "Epoch 401/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4085e-04 - mae: 0.0111 - val_loss: 0.0020 - val_mae: 0.0261\n",
      "Epoch 402/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7034e-04 - mae: 0.0138 - val_loss: 2.9330e-04 - val_mae: 0.0109\n",
      "Epoch 403/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7232e-04 - mae: 0.0121 - val_loss: 3.3049e-04 - val_mae: 0.0118\n",
      "Epoch 404/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 2.8553e-04 - mae: 0.0108 - val_loss: 2.8399e-04 - val_mae: 0.0106\n",
      "Epoch 405/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.0235e-04 - mae: 0.0113 - val_loss: 3.0943e-04 - val_mae: 0.0117\n",
      "Epoch 406/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8730e-04 - mae: 0.0128 - val_loss: 5.9858e-04 - val_mae: 0.0144\n",
      "Epoch 407/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0322e-04 - mae: 0.0131 - val_loss: 4.0057e-04 - val_mae: 0.0138\n",
      "Epoch 408/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.7877e-04 - mae: 0.0107 - val_loss: 3.1127e-04 - val_mae: 0.0111\n",
      "Epoch 409/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.3502e-04 - mae: 0.0132 - val_loss: 3.5747e-04 - val_mae: 0.0123\n",
      "Epoch 410/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.9638e-04 - mae: 0.0109 - val_loss: 2.9733e-04 - val_mae: 0.0111\n",
      "Epoch 411/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8352e-04 - mae: 0.0106 - val_loss: 5.5699e-04 - val_mae: 0.0140\n",
      "Epoch 412/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 6.5196e-04 - mae: 0.0164 - val_loss: 3.0925e-04 - val_mae: 0.0109\n",
      "Epoch 413/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.3403e-04 - mae: 0.0117 - val_loss: 3.5018e-04 - val_mae: 0.0116\n",
      "Epoch 414/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8636e-04 - mae: 0.0108 - val_loss: 2.4085e-04 - val_mae: 0.0096\n",
      "Epoch 415/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2655e-04 - mae: 0.0125 - val_loss: 5.4676e-04 - val_mae: 0.0151\n",
      "Epoch 416/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5868e-04 - mae: 0.0121 - val_loss: 3.2521e-04 - val_mae: 0.0112\n",
      "Epoch 417/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 4.5910e-04 - mae: 0.0132 - val_loss: 7.4867e-04 - val_mae: 0.0198\n",
      "Epoch 418/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6202e-04 - mae: 0.0123 - val_loss: 3.0878e-04 - val_mae: 0.0114\n",
      "Epoch 419/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4946e-04 - mae: 0.0120 - val_loss: 4.3290e-04 - val_mae: 0.0133\n",
      "Epoch 420/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 3.6748e-04 - mae: 0.0120 - val_loss: 3.0835e-04 - val_mae: 0.0113\n",
      "Epoch 421/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4214e-04 - mae: 0.0117 - val_loss: 5.2489e-04 - val_mae: 0.0152\n",
      "Epoch 422/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.9390e-04 - mae: 0.0125 - val_loss: 3.1768e-04 - val_mae: 0.0110\n",
      "Epoch 423/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.9471e-04 - mae: 0.0126 - val_loss: 3.8895e-04 - val_mae: 0.0142\n",
      "Epoch 424/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 5.0601e-04 - mae: 0.0136 - val_loss: 4.5738e-04 - val_mae: 0.0157\n",
      "Epoch 425/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.7085e-04 - mae: 0.0166 - val_loss: 2.9232e-04 - val_mae: 0.0108\n",
      "Epoch 426/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.3600e-04 - mae: 0.0115 - val_loss: 3.6631e-04 - val_mae: 0.0122\n",
      "Epoch 427/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9585e-04 - mae: 0.0107 - val_loss: 4.3315e-04 - val_mae: 0.0134\n",
      "Epoch 428/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.8175e-04 - mae: 0.0108 - val_loss: 2.6373e-04 - val_mae: 0.0100\n",
      "Epoch 429/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8202e-04 - mae: 0.0106 - val_loss: 4.2959e-04 - val_mae: 0.0129\n",
      "Epoch 430/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.0770e-04 - mae: 0.0131 - val_loss: 4.4965e-04 - val_mae: 0.0139\n",
      "Epoch 431/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.6781e-04 - mae: 0.0104 - val_loss: 5.5317e-04 - val_mae: 0.0133\n",
      "Epoch 432/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 3.9748e-04 - mae: 0.0130 - val_loss: 3.4961e-04 - val_mae: 0.0130\n",
      "Epoch 433/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8928e-04 - mae: 0.0125 - val_loss: 4.4140e-04 - val_mae: 0.0155\n",
      "Epoch 434/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.9781e-04 - mae: 0.0141 - val_loss: 6.6620e-04 - val_mae: 0.0135\n",
      "Epoch 435/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.0707e-04 - mae: 0.0111 - val_loss: 2.7244e-04 - val_mae: 0.0102\n",
      "Epoch 436/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8103e-04 - mae: 0.0105 - val_loss: 4.6503e-04 - val_mae: 0.0135\n",
      "Epoch 437/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.0565e-04 - mae: 0.0107 - val_loss: 3.5381e-04 - val_mae: 0.0127\n",
      "Epoch 438/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 3.1356e-04 - mae: 0.0116 - val_loss: 3.1249e-04 - val_mae: 0.0112\n",
      "Epoch 439/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.0636e-04 - mae: 0.0170 - val_loss: 4.8429e-04 - val_mae: 0.0152\n",
      "Epoch 440/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.2510e-04 - mae: 0.0114 - val_loss: 2.8556e-04 - val_mae: 0.0110\n",
      "Epoch 441/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.5159e-04 - mae: 0.0120 - val_loss: 3.9225e-04 - val_mae: 0.0136\n",
      "Epoch 442/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.8515e-04 - mae: 0.0107 - val_loss: 4.3227e-04 - val_mae: 0.0128\n",
      "Epoch 443/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.7534e-04 - mae: 0.0104 - val_loss: 2.4013e-04 - val_mae: 0.0101\n",
      "Epoch 444/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.3413e-04 - mae: 0.0118 - val_loss: 2.6597e-04 - val_mae: 0.0101\n",
      "Epoch 445/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.6475e-04 - mae: 0.0125 - val_loss: 6.9596e-04 - val_mae: 0.0154\n",
      "Epoch 446/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4867e-04 - mae: 0.0118 - val_loss: 7.8465e-04 - val_mae: 0.0150\n",
      "Epoch 447/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6301e-04 - mae: 0.0121 - val_loss: 3.4699e-04 - val_mae: 0.0107\n",
      "Epoch 448/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.7268e-04 - mae: 0.0101 - val_loss: 3.7606e-04 - val_mae: 0.0124\n",
      "Epoch 449/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.3249e-04 - mae: 0.0116 - val_loss: 6.8011e-04 - val_mae: 0.0140\n",
      "Epoch 450/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2518e-04 - mae: 0.0113 - val_loss: 4.1247e-04 - val_mae: 0.0134\n",
      "Epoch 451/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2963e-04 - mae: 0.0115 - val_loss: 3.5201e-04 - val_mae: 0.0115\n",
      "Epoch 452/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 5.1811e-04 - mae: 0.0141 - val_loss: 4.4867e-04 - val_mae: 0.0142\n",
      "Epoch 453/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4504e-04 - mae: 0.0118 - val_loss: 4.0455e-04 - val_mae: 0.0136\n",
      "Epoch 454/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.3281e-04 - mae: 0.0115 - val_loss: 7.1852e-04 - val_mae: 0.0216\n",
      "Epoch 455/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.7038e-04 - mae: 0.0124 - val_loss: 3.3749e-04 - val_mae: 0.0109\n",
      "Epoch 456/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9542e-04 - mae: 0.0106 - val_loss: 3.6264e-04 - val_mae: 0.0115\n",
      "Epoch 457/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.7063e-04 - mae: 0.0103 - val_loss: 2.7157e-04 - val_mae: 0.0105\n",
      "Epoch 458/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.8132e-04 - mae: 0.0106 - val_loss: 2.2038e-04 - val_mae: 0.0089\n",
      "Epoch 459/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 2.6880e-04 - mae: 0.0104 - val_loss: 3.3620e-04 - val_mae: 0.0116\n",
      "Epoch 460/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4428e-04 - mae: 0.0119 - val_loss: 2.5609e-04 - val_mae: 0.0096\n",
      "Epoch 461/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8011e-04 - mae: 0.0122 - val_loss: 3.4863e-04 - val_mae: 0.0117\n",
      "Epoch 462/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.1178e-04 - mae: 0.0111 - val_loss: 3.2131e-04 - val_mae: 0.0116\n",
      "Epoch 463/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9437e-04 - mae: 0.0109 - val_loss: 2.3777e-04 - val_mae: 0.0094\n",
      "Epoch 464/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.9176e-04 - mae: 0.0112 - val_loss: 2.6011e-04 - val_mae: 0.0110\n",
      "Epoch 465/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.2056e-04 - mae: 0.0119 - val_loss: 3.2060e-04 - val_mae: 0.0113\n",
      "Epoch 466/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.8565e-04 - mae: 0.0107 - val_loss: 2.9381e-04 - val_mae: 0.0110\n",
      "Epoch 467/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.2535e-04 - mae: 0.0113 - val_loss: 3.2556e-04 - val_mae: 0.0119\n",
      "Epoch 468/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4078e-04 - mae: 0.0130 - val_loss: 3.1454e-04 - val_mae: 0.0107\n",
      "Epoch 469/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6764e-04 - mae: 0.0139 - val_loss: 2.7321e-04 - val_mae: 0.0111\n",
      "Epoch 470/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.6842e-04 - mae: 0.0103 - val_loss: 4.1637e-04 - val_mae: 0.0130\n",
      "Epoch 471/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4411e-04 - mae: 0.0114 - val_loss: 2.9331e-04 - val_mae: 0.0099\n",
      "Epoch 472/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2.4951e-04 - mae: 0.0101 - val_loss: 3.3900e-04 - val_mae: 0.0126\n",
      "Epoch 473/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 4.5982e-04 - mae: 0.0133 - val_loss: 3.7220e-04 - val_mae: 0.0125\n",
      "Epoch 474/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.0811e-04 - mae: 0.0113 - val_loss: 4.2116e-04 - val_mae: 0.0141\n",
      "Epoch 475/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4717e-04 - mae: 0.0117 - val_loss: 4.7289e-04 - val_mae: 0.0127\n",
      "Epoch 476/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.1584e-04 - mae: 0.0112 - val_loss: 2.4292e-04 - val_mae: 0.0100\n",
      "Epoch 477/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.3440e-04 - mae: 0.0098 - val_loss: 2.5372e-04 - val_mae: 0.0103\n",
      "Epoch 478/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5644e-04 - mae: 0.0132 - val_loss: 8.0620e-04 - val_mae: 0.0165\n",
      "Epoch 479/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 2.9363e-04 - mae: 0.0108 - val_loss: 3.2970e-04 - val_mae: 0.0105\n",
      "Epoch 480/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9127e-04 - mae: 0.0107 - val_loss: 2.4454e-04 - val_mae: 0.0102\n",
      "Epoch 481/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.6225e-04 - mae: 0.0120 - val_loss: 2.4117e-04 - val_mae: 0.0103\n",
      "Epoch 482/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.7919e-04 - mae: 0.0125 - val_loss: 2.5601e-04 - val_mae: 0.0098\n",
      "Epoch 483/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2981e-04 - mae: 0.0110 - val_loss: 4.0128e-04 - val_mae: 0.0123\n",
      "Epoch 484/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2708e-04 - mae: 0.0142 - val_loss: 6.2075e-04 - val_mae: 0.0180\n",
      "Epoch 485/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.7979e-04 - mae: 0.0125 - val_loss: 3.4264e-04 - val_mae: 0.0135\n",
      "Epoch 486/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.0581e-04 - mae: 0.0114 - val_loss: 6.0653e-04 - val_mae: 0.0147\n",
      "Epoch 487/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.0319e-04 - mae: 0.0111 - val_loss: 3.1606e-04 - val_mae: 0.0116\n",
      "Epoch 488/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 2.6372e-04 - mae: 0.0104 - val_loss: 2.6562e-04 - val_mae: 0.0097\n",
      "Epoch 488: early stopping\n",
      "Loss: 0.0002656226570252329, MAE: 0.009741054847836494\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "R² score for output 1: 0.9998409386805333\n",
      "R² score for output 2: 0.9997392086297389\n",
      "R² score for output 3: 0.9996372003875149\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "scalery = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scalery.fit_transform(y_train)\n",
    "y_test = scalery.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='linear')  # 3 outputs: cl, cd, cm\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test,y_test), callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss}, MAE: {mae}\")\n",
    "\n",
    "# CNN2: Loss: 0.0032769939862191677, MAE: 0.038386013358831406\n",
    "# CNN3: Loss: 0.0012407711474224925, MAE: 0.025044899433851242\n",
    "# CNN4: Loss: 0.0007000479381531477, MAE: 0.017104944214224815\n",
    "# CNN5: Loss: 0.0006939252489246428, MAE: 0.016976164653897285\n",
    "# CNN6: Loss: 0.0005698658060282469, MAE: 0.01500221062451601\n",
    "# CNN7：Loss: 0.0002656226570252329, MAE: 0.009741054847836494 (final model)\n",
    "\n",
    "# R2-score\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scalery.inverse_transform(y_pred)\n",
    "y_test = scalery.inverse_transform(y_test)\n",
    "r2_scores = [r2_score(y_test[:, i], y_pred[:, i]) for i in range(y_test.shape[1])]\n",
    "for i, r2 in enumerate(r2_scores):\n",
    "    print(f\"R² score for output {i+1}: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               512       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,539\n",
      "Trainable params: 11,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curve\n",
    "losses = pd.DataFrame(history.history)\n",
    "plt.plot(losses.index, losses['loss'], label='train_loss')\n",
    "plt.plot(losses.index, losses['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file\n",
    "model.save('clark-y-cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
