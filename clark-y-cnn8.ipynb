{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: 根据已有数据创建神经网络ANN\n",
    "'''\n",
    "conda create -n myenv python=3.8\n",
    "conda activate myenv\n",
    "\n",
    "conda install numpy pandas scikit-learn\n",
    "conda install -c conda-forge tensorflow\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('clark-y-2.csv')\n",
    "\n",
    "# Filter the data\n",
    "filtered_df = df[\n",
    "    (df['Reynold'] >= 0.1e5) & (df['Reynold'] <= 40e5) &  # 雷诺数范围\n",
    "    (df['Mach'] >= 0.1) & (df['Mach'] <= 0.7) &            # 马赫数范围\n",
    "    (df['Alpha'] >= -3) & (df['Alpha'] <= 15)              # 迎角范围\n",
    "]\n",
    "\n",
    "# Split the data into inputs (X) and outputs (y)\n",
    "X = filtered_df[['Reynold', 'Mach', 'Alpha']].values\n",
    "y = filtered_df[['cl', 'cd', 'cm']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "125/125 [==============================] - 2s 6ms/step - loss: 1.0287 - mae: 0.7376 - val_loss: 0.7055 - val_mae: 0.6389\n",
      "Epoch 2/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5890 - mae: 0.5370 - val_loss: 0.4165 - val_mae: 0.4356\n",
      "Epoch 3/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4401 - mae: 0.4242 - val_loss: 0.3400 - val_mae: 0.3763\n",
      "Epoch 4/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3818 - mae: 0.3777 - val_loss: 0.3019 - val_mae: 0.3434\n",
      "Epoch 5/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3528 - mae: 0.3553 - val_loss: 0.2817 - val_mae: 0.3330\n",
      "Epoch 6/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3323 - mae: 0.3442 - val_loss: 0.2628 - val_mae: 0.3161\n",
      "Epoch 7/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3096 - mae: 0.3268 - val_loss: 0.2391 - val_mae: 0.2974\n",
      "Epoch 8/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2644 - mae: 0.2973 - val_loss: 0.1894 - val_mae: 0.2528\n",
      "Epoch 9/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2121 - mae: 0.2508 - val_loss: 0.1555 - val_mae: 0.2232\n",
      "Epoch 10/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1694 - mae: 0.2200 - val_loss: 0.1200 - val_mae: 0.1895\n",
      "Epoch 11/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1363 - mae: 0.1969 - val_loss: 0.1000 - val_mae: 0.1774\n",
      "Epoch 12/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.1114 - mae: 0.1804 - val_loss: 0.0830 - val_mae: 0.1690\n",
      "Epoch 13/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0931 - mae: 0.1676 - val_loss: 0.0681 - val_mae: 0.1525\n",
      "Epoch 14/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0797 - mae: 0.1580 - val_loss: 0.0608 - val_mae: 0.1471\n",
      "Epoch 15/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0703 - mae: 0.1492 - val_loss: 0.0524 - val_mae: 0.1360\n",
      "Epoch 16/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0627 - mae: 0.1416 - val_loss: 0.0494 - val_mae: 0.1318\n",
      "Epoch 17/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0572 - mae: 0.1355 - val_loss: 0.0446 - val_mae: 0.1259\n",
      "Epoch 18/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0527 - mae: 0.1301 - val_loss: 0.0413 - val_mae: 0.1212\n",
      "Epoch 19/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1255 - val_loss: 0.0390 - val_mae: 0.1170\n",
      "Epoch 20/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0456 - mae: 0.1216 - val_loss: 0.0366 - val_mae: 0.1140\n",
      "Epoch 21/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.1189 - val_loss: 0.0356 - val_mae: 0.1125\n",
      "Epoch 22/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0407 - mae: 0.1162 - val_loss: 0.0334 - val_mae: 0.1089\n",
      "Epoch 23/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0385 - mae: 0.1132 - val_loss: 0.0347 - val_mae: 0.1098\n",
      "Epoch 24/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0381 - mae: 0.1132 - val_loss: 0.0338 - val_mae: 0.1074\n",
      "Epoch 25/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1090 - val_loss: 0.0318 - val_mae: 0.1078\n",
      "Epoch 26/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0327 - mae: 0.1055 - val_loss: 0.0283 - val_mae: 0.1018\n",
      "Epoch 27/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0317 - mae: 0.1040 - val_loss: 0.0263 - val_mae: 0.0960\n",
      "Epoch 28/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0994 - val_loss: 0.0243 - val_mae: 0.0944\n",
      "Epoch 29/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0272 - mae: 0.0959 - val_loss: 0.0224 - val_mae: 0.0906\n",
      "Epoch 30/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.0273 - mae: 0.0957 - val_loss: 0.0216 - val_mae: 0.0892\n",
      "Epoch 31/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0238 - mae: 0.0887 - val_loss: 0.0201 - val_mae: 0.0859\n",
      "Epoch 32/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0225 - mae: 0.0862 - val_loss: 0.0186 - val_mae: 0.0807\n",
      "Epoch 33/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - mae: 0.0820 - val_loss: 0.0182 - val_mae: 0.0811\n",
      "Epoch 34/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.0792 - val_loss: 0.0167 - val_mae: 0.0758\n",
      "Epoch 35/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0771 - val_loss: 0.0173 - val_mae: 0.0757\n",
      "Epoch 36/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0181 - mae: 0.0770 - val_loss: 0.0154 - val_mae: 0.0728\n",
      "Epoch 37/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0744 - val_loss: 0.0142 - val_mae: 0.0684\n",
      "Epoch 38/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0720 - val_loss: 0.0138 - val_mae: 0.0681\n",
      "Epoch 39/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0696 - val_loss: 0.0137 - val_mae: 0.0676\n",
      "Epoch 40/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0687 - val_loss: 0.0126 - val_mae: 0.0658\n",
      "Epoch 41/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0681 - val_loss: 0.0116 - val_mae: 0.0631\n",
      "Epoch 42/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0668 - val_loss: 0.0112 - val_mae: 0.0634\n",
      "Epoch 43/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0121 - mae: 0.0638 - val_loss: 0.0103 - val_mae: 0.0598\n",
      "Epoch 44/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0125 - mae: 0.0657 - val_loss: 0.0111 - val_mae: 0.0660\n",
      "Epoch 45/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0113 - mae: 0.0629 - val_loss: 0.0088 - val_mae: 0.0561\n",
      "Epoch 46/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0097 - mae: 0.0583 - val_loss: 0.0081 - val_mae: 0.0537\n",
      "Epoch 47/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0092 - mae: 0.0568 - val_loss: 0.0090 - val_mae: 0.0577\n",
      "Epoch 48/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0600 - val_loss: 0.0069 - val_mae: 0.0507\n",
      "Epoch 49/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0522 - val_loss: 0.0066 - val_mae: 0.0497\n",
      "Epoch 50/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0073 - mae: 0.0516 - val_loss: 0.0060 - val_mae: 0.0479\n",
      "Epoch 51/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0068 - mae: 0.0504 - val_loss: 0.0059 - val_mae: 0.0480\n",
      "Epoch 52/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0067 - mae: 0.0504 - val_loss: 0.0056 - val_mae: 0.0477\n",
      "Epoch 53/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0494 - val_loss: 0.0057 - val_mae: 0.0473\n",
      "Epoch 54/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0523 - val_loss: 0.0054 - val_mae: 0.0469\n",
      "Epoch 55/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0499 - val_loss: 0.0064 - val_mae: 0.0555\n",
      "Epoch 56/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0478 - val_loss: 0.0064 - val_mae: 0.0491\n",
      "Epoch 57/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0060 - mae: 0.0488 - val_loss: 0.0047 - val_mae: 0.0447\n",
      "Epoch 58/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0053 - mae: 0.0460 - val_loss: 0.0044 - val_mae: 0.0428\n",
      "Epoch 59/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0445 - val_loss: 0.0046 - val_mae: 0.0441\n",
      "Epoch 60/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0050 - mae: 0.0446 - val_loss: 0.0042 - val_mae: 0.0422\n",
      "Epoch 61/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0057 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0410\n",
      "Epoch 62/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0047 - mae: 0.0431 - val_loss: 0.0037 - val_mae: 0.0400\n",
      "Epoch 63/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0048 - mae: 0.0437 - val_loss: 0.0037 - val_mae: 0.0401\n",
      "Epoch 64/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0043 - mae: 0.0414 - val_loss: 0.0037 - val_mae: 0.0401\n",
      "Epoch 65/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0063 - mae: 0.0499 - val_loss: 0.0041 - val_mae: 0.0438\n",
      "Epoch 66/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0415 - val_loss: 0.0033 - val_mae: 0.0388\n",
      "Epoch 67/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0387 - val_loss: 0.0031 - val_mae: 0.0367\n",
      "Epoch 68/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0379 - val_loss: 0.0028 - val_mae: 0.0353\n",
      "Epoch 69/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0378 - val_loss: 0.0027 - val_mae: 0.0356\n",
      "Epoch 70/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0365 - val_loss: 0.0025 - val_mae: 0.0339\n",
      "Epoch 71/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.0029 - val_mae: 0.0352\n",
      "Epoch 72/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0023 - val_mae: 0.0329\n",
      "Epoch 73/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0339 - val_loss: 0.0024 - val_mae: 0.0343\n",
      "Epoch 74/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0323 - val_loss: 0.0022 - val_mae: 0.0320\n",
      "Epoch 75/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 76/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0021 - val_mae: 0.0306\n",
      "Epoch 77/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0022 - val_mae: 0.0312\n",
      "Epoch 78/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0309 - val_loss: 0.0016 - val_mae: 0.0274\n",
      "Epoch 79/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0301 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 80/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0306 - val_loss: 0.0019 - val_mae: 0.0293\n",
      "Epoch 81/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 82/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 0.0018 - val_mae: 0.0291\n",
      "Epoch 83/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0020 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0268\n",
      "Epoch 84/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 85/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0015 - val_mae: 0.0270\n",
      "Epoch 86/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0018 - val_mae: 0.0295\n",
      "Epoch 87/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 88/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0018 - val_mae: 0.0279\n",
      "Epoch 89/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0024 - mae: 0.0319 - val_loss: 0.0014 - val_mae: 0.0260\n",
      "Epoch 90/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0020 - val_mae: 0.0300\n",
      "Epoch 91/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 92/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0262\n",
      "Epoch 93/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 94/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 95/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 96/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 97/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 98/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 99/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 100/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 101/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0268\n",
      "Epoch 102/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 103/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0014 - val_mae: 0.0254\n",
      "Epoch 104/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 105/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0029 - mae: 0.0356 - val_loss: 0.0023 - val_mae: 0.0364\n",
      "Epoch 106/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 107/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 9.7026e-04 - val_mae: 0.0215\n",
      "Epoch 108/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 9.2602e-04 - val_mae: 0.0211\n",
      "Epoch 109/1000\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 8.9183e-04 - val_mae: 0.0207\n",
      "Epoch 110/1000\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 111/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 8.5437e-04 - val_mae: 0.0203\n",
      "Epoch 112/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 8.9681e-04 - val_mae: 0.0208\n",
      "Epoch 113/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 9.4659e-04 - val_mae: 0.0213\n",
      "Epoch 114/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 9.5936e-04 - val_mae: 0.0216\n",
      "Epoch 115/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 9.1780e-04 - val_mae: 0.0211\n",
      "Epoch 116/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 117/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 118/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 9.4576e-04 - val_mae: 0.0205\n",
      "Epoch 119/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 120/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 8.9951e-04 - val_mae: 0.0212\n",
      "Epoch 121/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 8.0188e-04 - val_mae: 0.0200\n",
      "Epoch 122/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 8.7214e-04 - val_mae: 0.0209\n",
      "Epoch 123/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0310 - val_loss: 0.0025 - val_mae: 0.0302\n",
      "Epoch 124/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 9.0948e-04 - val_mae: 0.0209\n",
      "Epoch 125/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.8998e-04 - mae: 0.0207 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 126/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 8.9336e-04 - val_mae: 0.0209\n",
      "Epoch 127/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 9.2865e-04 - mae: 0.0202 - val_loss: 8.0716e-04 - val_mae: 0.0201\n",
      "Epoch 128/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 9.1945e-04 - val_mae: 0.0221\n",
      "Epoch 129/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 130/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 131/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 132/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9036e-04 - mae: 0.0209 - val_loss: 7.3443e-04 - val_mae: 0.0190\n",
      "Epoch 133/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 134/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 9.7687e-04 - val_mae: 0.0214\n",
      "Epoch 135/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4111e-04 - mae: 0.0203 - val_loss: 8.6069e-04 - val_mae: 0.0208\n",
      "Epoch 136/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 6.9475e-04 - val_mae: 0.0187\n",
      "Epoch 137/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5832e-04 - mae: 0.0192 - val_loss: 7.2732e-04 - val_mae: 0.0186\n",
      "Epoch 138/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 139/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.5553e-04 - mae: 0.0206 - val_loss: 7.2317e-04 - val_mae: 0.0186\n",
      "Epoch 140/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2280e-04 - mae: 0.0202 - val_loss: 9.7762e-04 - val_mae: 0.0229\n",
      "Epoch 141/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.6816e-04 - mae: 0.0195 - val_loss: 7.4138e-04 - val_mae: 0.0195\n",
      "Epoch 142/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "Epoch 143/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 6.2967e-04 - val_mae: 0.0172\n",
      "Epoch 144/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 7.0872e-04 - val_mae: 0.0184\n",
      "Epoch 145/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2902e-04 - mae: 0.0190 - val_loss: 6.7706e-04 - val_mae: 0.0181\n",
      "Epoch 146/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.1023e-04 - mae: 0.0199 - val_loss: 9.6041e-04 - val_mae: 0.0234\n",
      "Epoch 147/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.4964e-04 - mae: 0.0194 - val_loss: 7.5487e-04 - val_mae: 0.0196\n",
      "Epoch 148/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.6221e-04 - mae: 0.0208 - val_loss: 8.1966e-04 - val_mae: 0.0193\n",
      "Epoch 149/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.5807e-04 - mae: 0.0198 - val_loss: 6.8026e-04 - val_mae: 0.0178\n",
      "Epoch 150/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7813e-04 - mae: 0.0198 - val_loss: 7.1283e-04 - val_mae: 0.0187\n",
      "Epoch 151/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4252e-04 - mae: 0.0200 - val_loss: 7.2194e-04 - val_mae: 0.0191\n",
      "Epoch 152/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2927e-04 - mae: 0.0193 - val_loss: 6.3375e-04 - val_mae: 0.0173\n",
      "Epoch 153/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7640e-04 - mae: 0.0199 - val_loss: 9.8999e-04 - val_mae: 0.0217\n",
      "Epoch 154/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.1181e-04 - mae: 0.0191 - val_loss: 6.3582e-04 - val_mae: 0.0176\n",
      "Epoch 155/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.7742e-04 - mae: 0.0201 - val_loss: 6.0488e-04 - val_mae: 0.0170\n",
      "Epoch 156/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.2349e-04 - mae: 0.0188 - val_loss: 7.9186e-04 - val_mae: 0.0198\n",
      "Epoch 157/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 6.8042e-04 - val_mae: 0.0174\n",
      "Epoch 158/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.8338e-04 - mae: 0.0185 - val_loss: 7.5457e-04 - val_mae: 0.0196\n",
      "Epoch 159/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.4768e-04 - mae: 0.0208 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 160/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.9816e-04 - mae: 0.0212 - val_loss: 7.7773e-04 - val_mae: 0.0188\n",
      "Epoch 161/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.2739e-04 - mae: 0.0197 - val_loss: 5.9170e-04 - val_mae: 0.0164\n",
      "Epoch 162/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.4240e-04 - mae: 0.0179 - val_loss: 5.8051e-04 - val_mae: 0.0163\n",
      "Epoch 163/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.7195e-04 - mae: 0.0186 - val_loss: 9.0091e-04 - val_mae: 0.0218\n",
      "Epoch 164/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0216 - val_loss: 0.0022 - val_mae: 0.0301\n",
      "Epoch 165/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.9821e-04 - mae: 0.0192 - val_loss: 5.8452e-04 - val_mae: 0.0163\n",
      "Epoch 166/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.0633e-04 - mae: 0.0189 - val_loss: 8.2167e-04 - val_mae: 0.0190\n",
      "Epoch 167/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 7.4187e-04 - mae: 0.0181 - val_loss: 5.6733e-04 - val_mae: 0.0164\n",
      "Epoch 168/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 7.7707e-04 - mae: 0.0187 - val_loss: 6.6242e-04 - val_mae: 0.0184\n",
      "Epoch 169/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 8.2950e-04 - mae: 0.0190 - val_loss: 6.6012e-04 - val_mae: 0.0176\n",
      "Epoch 170/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.3415e-04 - mae: 0.0181 - val_loss: 5.8308e-04 - val_mae: 0.0160\n",
      "Epoch 171/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 9.3153e-04 - mae: 0.0196 - val_loss: 0.0046 - val_mae: 0.0381\n",
      "Epoch 172/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 6.5879e-04 - val_mae: 0.0175\n",
      "Epoch 173/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.2154e-04 - mae: 0.0176 - val_loss: 5.8396e-04 - val_mae: 0.0166\n",
      "Epoch 174/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 7.3813e-04 - mae: 0.0179 - val_loss: 5.6707e-04 - val_mae: 0.0156\n",
      "Epoch 175/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.8345e-04 - mae: 0.0184 - val_loss: 5.4914e-04 - val_mae: 0.0160\n",
      "Epoch 176/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.4516e-04 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0200\n",
      "Epoch 177/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.1100e-04 - mae: 0.0178 - val_loss: 6.5783e-04 - val_mae: 0.0179\n",
      "Epoch 178/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.7324e-04 - mae: 0.0188 - val_loss: 7.8901e-04 - val_mae: 0.0210\n",
      "Epoch 179/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.3398e-04 - mae: 0.0179 - val_loss: 6.7889e-04 - val_mae: 0.0169\n",
      "Epoch 180/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.7366e-04 - mae: 0.0203 - val_loss: 4.9813e-04 - val_mae: 0.0156\n",
      "Epoch 181/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 8.9657e-04 - mae: 0.0200 - val_loss: 8.9160e-04 - val_mae: 0.0223\n",
      "Epoch 182/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 9.5331e-04 - mae: 0.0205 - val_loss: 4.8573e-04 - val_mae: 0.0149\n",
      "Epoch 183/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 8.1659e-04 - mae: 0.0192 - val_loss: 7.4659e-04 - val_mae: 0.0185\n",
      "Epoch 184/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.8556e-04 - mae: 0.0174 - val_loss: 6.2839e-04 - val_mae: 0.0188\n",
      "Epoch 185/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.1843e-04 - mae: 0.0179 - val_loss: 6.1306e-04 - val_mae: 0.0176\n",
      "Epoch 186/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.3347e-04 - mae: 0.0180 - val_loss: 8.4587e-04 - val_mae: 0.0185\n",
      "Epoch 187/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.9091e-04 - val_mae: 0.0186\n",
      "Epoch 188/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 9.3695e-04 - mae: 0.0198 - val_loss: 6.3976e-04 - val_mae: 0.0181\n",
      "Epoch 189/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.7132e-04 - mae: 0.0172 - val_loss: 4.5677e-04 - val_mae: 0.0148\n",
      "Epoch 190/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 7.6140e-04 - mae: 0.0180 - val_loss: 6.1078e-04 - val_mae: 0.0181\n",
      "Epoch 191/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.8528e-04 - mae: 0.0156 - val_loss: 6.5900e-04 - val_mae: 0.0177\n",
      "Epoch 192/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.5472e-04 - mae: 0.0166 - val_loss: 7.3921e-04 - val_mae: 0.0187\n",
      "Epoch 193/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.5510e-04 - mae: 0.0172 - val_loss: 4.7746e-04 - val_mae: 0.0152\n",
      "Epoch 194/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 7.3158e-04 - mae: 0.0176 - val_loss: 8.3535e-04 - val_mae: 0.0201\n",
      "Epoch 195/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 7.3188e-04 - mae: 0.0182 - val_loss: 6.1266e-04 - val_mae: 0.0174\n",
      "Epoch 196/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1835e-04 - mae: 0.0166 - val_loss: 5.5770e-04 - val_mae: 0.0165\n",
      "Epoch 197/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.8895e-04 - mae: 0.0175 - val_loss: 5.6991e-04 - val_mae: 0.0164\n",
      "Epoch 198/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.7663e-04 - mae: 0.0171 - val_loss: 6.1338e-04 - val_mae: 0.0167\n",
      "Epoch 199/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.1953e-04 - mae: 0.0178 - val_loss: 7.3830e-04 - val_mae: 0.0177\n",
      "Epoch 200/1000\n",
      "125/125 [==============================] - 1s 11ms/step - loss: 6.5152e-04 - mae: 0.0171 - val_loss: 6.9305e-04 - val_mae: 0.0163\n",
      "Epoch 201/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 6.6735e-04 - mae: 0.0172 - val_loss: 8.2338e-04 - val_mae: 0.0190\n",
      "Epoch 202/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 8.5289e-04 - mae: 0.0195 - val_loss: 5.4021e-04 - val_mae: 0.0175\n",
      "Epoch 203/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 7.8667e-04 - mae: 0.0181 - val_loss: 9.5843e-04 - val_mae: 0.0233\n",
      "Epoch 204/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1891e-04 - mae: 0.0181 - val_loss: 4.3111e-04 - val_mae: 0.0142\n",
      "Epoch 205/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.4618e-04 - mae: 0.0169 - val_loss: 5.1475e-04 - val_mae: 0.0161\n",
      "Epoch 206/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.2663e-04 - mae: 0.0165 - val_loss: 6.1561e-04 - val_mae: 0.0174\n",
      "Epoch 207/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 6.7775e-04 - mae: 0.0171 - val_loss: 5.1707e-04 - val_mae: 0.0158\n",
      "Epoch 208/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 6.6596e-04 - mae: 0.0170 - val_loss: 5.0958e-04 - val_mae: 0.0152\n",
      "Epoch 209/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.5273e-04 - mae: 0.0188 - val_loss: 6.0437e-04 - val_mae: 0.0171\n",
      "Epoch 210/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 6.7423e-04 - mae: 0.0166 - val_loss: 0.0017 - val_mae: 0.0267\n",
      "Epoch 211/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.9172e-04 - mae: 0.0202 - val_loss: 4.5225e-04 - val_mae: 0.0146\n",
      "Epoch 212/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.5679e-04 - mae: 0.0168 - val_loss: 9.9044e-04 - val_mae: 0.0197\n",
      "Epoch 213/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 7.0170e-04 - mae: 0.0176 - val_loss: 4.8650e-04 - val_mae: 0.0155\n",
      "Epoch 214/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 7.2128e-04 - mae: 0.0175 - val_loss: 6.8791e-04 - val_mae: 0.0187\n",
      "Epoch 215/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.1430e-04 - mae: 0.0188 - val_loss: 4.7931e-04 - val_mae: 0.0152\n",
      "Epoch 216/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.5514e-04 - mae: 0.0155 - val_loss: 5.2699e-04 - val_mae: 0.0162\n",
      "Epoch 217/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.7086e-04 - mae: 0.0159 - val_loss: 4.1545e-04 - val_mae: 0.0140\n",
      "Epoch 218/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.2325e-04 - mae: 0.0167 - val_loss: 4.7861e-04 - val_mae: 0.0146\n",
      "Epoch 219/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 5.8984e-04 - mae: 0.0161 - val_loss: 5.9243e-04 - val_mae: 0.0153\n",
      "Epoch 220/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.3720e-04 - mae: 0.0151 - val_loss: 4.6341e-04 - val_mae: 0.0150\n",
      "Epoch 221/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.7444e-04 - mae: 0.0192 - val_loss: 4.6749e-04 - val_mae: 0.0158\n",
      "Epoch 222/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.5069e-04 - mae: 0.0170 - val_loss: 6.3175e-04 - val_mae: 0.0180\n",
      "Epoch 223/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.7882e-04 - mae: 0.0192 - val_loss: 5.7289e-04 - val_mae: 0.0169\n",
      "Epoch 224/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1378e-04 - mae: 0.0176 - val_loss: 5.2796e-04 - val_mae: 0.0153\n",
      "Epoch 225/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.0166e-04 - mae: 0.0163 - val_loss: 4.5235e-04 - val_mae: 0.0145\n",
      "Epoch 226/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 5.3978e-04 - mae: 0.0152 - val_loss: 9.2353e-04 - val_mae: 0.0227\n",
      "Epoch 227/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.8384e-04 - mae: 0.0161 - val_loss: 4.7200e-04 - val_mae: 0.0141\n",
      "Epoch 228/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.0986e-04 - mae: 0.0161 - val_loss: 5.4747e-04 - val_mae: 0.0163\n",
      "Epoch 229/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.3908e-04 - mae: 0.0170 - val_loss: 4.4873e-04 - val_mae: 0.0147\n",
      "Epoch 230/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.2810e-04 - mae: 0.0178 - val_loss: 5.0021e-04 - val_mae: 0.0143\n",
      "Epoch 231/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.7601e-04 - mae: 0.0157 - val_loss: 4.0030e-04 - val_mae: 0.0129\n",
      "Epoch 232/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.4589e-04 - mae: 0.0153 - val_loss: 5.8017e-04 - val_mae: 0.0156\n",
      "Epoch 233/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 8.1776e-04 - mae: 0.0188 - val_loss: 5.5742e-04 - val_mae: 0.0160\n",
      "Epoch 234/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.2020e-04 - mae: 0.0166 - val_loss: 4.4470e-04 - val_mae: 0.0147\n",
      "Epoch 235/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.1033e-04 - mae: 0.0146 - val_loss: 4.4322e-04 - val_mae: 0.0140\n",
      "Epoch 236/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.0241e-04 - mae: 0.0148 - val_loss: 6.5781e-04 - val_mae: 0.0162\n",
      "Epoch 237/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.5511e-04 - mae: 0.0155 - val_loss: 4.3275e-04 - val_mae: 0.0143\n",
      "Epoch 238/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.8007e-04 - mae: 0.0173 - val_loss: 4.0651e-04 - val_mae: 0.0138\n",
      "Epoch 239/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 7.1148e-04 - mae: 0.0170 - val_loss: 6.8944e-04 - val_mae: 0.0181\n",
      "Epoch 240/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.4729e-04 - mae: 0.0167 - val_loss: 4.2324e-04 - val_mae: 0.0140\n",
      "Epoch 241/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.9049e-04 - mae: 0.0145 - val_loss: 6.9232e-04 - val_mae: 0.0175\n",
      "Epoch 242/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 5.4618e-04 - mae: 0.0157 - val_loss: 4.3372e-04 - val_mae: 0.0145\n",
      "Epoch 243/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.4727e-04 - mae: 0.0153 - val_loss: 5.1270e-04 - val_mae: 0.0164\n",
      "Epoch 244/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1925e-04 - mae: 0.0150 - val_loss: 6.2865e-04 - val_mae: 0.0177\n",
      "Epoch 245/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.9300e-04 - mae: 0.0148 - val_loss: 4.1421e-04 - val_mae: 0.0145\n",
      "Epoch 246/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.0021 - mae: 0.0275 - val_loss: 9.9050e-04 - val_mae: 0.0216\n",
      "Epoch 247/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.3787e-04 - mae: 0.0153 - val_loss: 4.3693e-04 - val_mae: 0.0135\n",
      "Epoch 248/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.6827e-04 - mae: 0.0142 - val_loss: 5.1513e-04 - val_mae: 0.0145\n",
      "Epoch 249/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.5075e-04 - mae: 0.0153 - val_loss: 4.2334e-04 - val_mae: 0.0127\n",
      "Epoch 250/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.9410e-04 - mae: 0.0147 - val_loss: 5.0234e-04 - val_mae: 0.0156\n",
      "Epoch 251/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.3872e-04 - mae: 0.0154 - val_loss: 4.4554e-04 - val_mae: 0.0147\n",
      "Epoch 252/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0222 - val_loss: 8.4797e-04 - val_mae: 0.0200\n",
      "Epoch 253/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.5251e-04 - mae: 0.0153 - val_loss: 4.0723e-04 - val_mae: 0.0139\n",
      "Epoch 254/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.2992e-04 - mae: 0.0134 - val_loss: 3.9396e-04 - val_mae: 0.0131\n",
      "Epoch 255/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.3915e-04 - mae: 0.0136 - val_loss: 3.8384e-04 - val_mae: 0.0133\n",
      "Epoch 256/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.1026e-04 - mae: 0.0131 - val_loss: 4.6021e-04 - val_mae: 0.0140\n",
      "Epoch 257/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.7337e-04 - mae: 0.0152 - val_loss: 5.2238e-04 - val_mae: 0.0142\n",
      "Epoch 258/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7701e-04 - mae: 0.0142 - val_loss: 5.5683e-04 - val_mae: 0.0144\n",
      "Epoch 259/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.5499e-04 - mae: 0.0141 - val_loss: 3.3452e-04 - val_mae: 0.0122\n",
      "Epoch 260/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0016 - mae: 0.0246 - val_loss: 6.6332e-04 - val_mae: 0.0162\n",
      "Epoch 261/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.5666e-04 - mae: 0.0157 - val_loss: 4.3427e-04 - val_mae: 0.0137\n",
      "Epoch 262/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.5435e-04 - mae: 0.0137 - val_loss: 3.7673e-04 - val_mae: 0.0136\n",
      "Epoch 263/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.9500e-04 - mae: 0.0145 - val_loss: 3.3610e-04 - val_mae: 0.0126\n",
      "Epoch 264/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.3793e-04 - mae: 0.0135 - val_loss: 5.5907e-04 - val_mae: 0.0148\n",
      "Epoch 265/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.6778e-04 - mae: 0.0141 - val_loss: 4.1060e-04 - val_mae: 0.0133\n",
      "Epoch 266/1000\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 5.3082e-04 - mae: 0.0151 - val_loss: 3.2941e-04 - val_mae: 0.0120\n",
      "Epoch 267/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.6706e-04 - mae: 0.0141 - val_loss: 3.9924e-04 - val_mae: 0.0133\n",
      "Epoch 268/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 5.0136e-04 - mae: 0.0147 - val_loss: 3.4466e-04 - val_mae: 0.0125\n",
      "Epoch 269/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5097e-04 - mae: 0.0140 - val_loss: 4.8207e-04 - val_mae: 0.0144\n",
      "Epoch 270/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.4671e-04 - mae: 0.0139 - val_loss: 3.6423e-04 - val_mae: 0.0128\n",
      "Epoch 271/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 5.1314e-04 - mae: 0.0151 - val_loss: 5.2505e-04 - val_mae: 0.0162\n",
      "Epoch 272/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.3921e-04 - mae: 0.0138 - val_loss: 3.8688e-04 - val_mae: 0.0136\n",
      "Epoch 273/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 5.3955e-04 - mae: 0.0155 - val_loss: 4.2740e-04 - val_mae: 0.0148\n",
      "Epoch 274/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1238e-04 - mae: 0.0134 - val_loss: 4.2522e-04 - val_mae: 0.0133\n",
      "Epoch 275/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 5.0528e-04 - mae: 0.0150 - val_loss: 4.1306e-04 - val_mae: 0.0135\n",
      "Epoch 276/1000\n",
      "125/125 [==============================] - 2s 11ms/step - loss: 5.2266e-04 - mae: 0.0151 - val_loss: 4.1440e-04 - val_mae: 0.0132\n",
      "Epoch 277/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 4.6855e-04 - mae: 0.0145 - val_loss: 3.8793e-04 - val_mae: 0.0132\n",
      "Epoch 278/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.9355e-04 - mae: 0.0204 - val_loss: 8.7882e-04 - val_mae: 0.0230\n",
      "Epoch 279/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.7194e-04 - mae: 0.0145 - val_loss: 3.4495e-04 - val_mae: 0.0119\n",
      "Epoch 280/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.4624e-04 - mae: 0.0151 - val_loss: 6.4330e-04 - val_mae: 0.0176\n",
      "Epoch 281/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.4680e-04 - mae: 0.0152 - val_loss: 7.2644e-04 - val_mae: 0.0173\n",
      "Epoch 282/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 7.0675e-04 - mae: 0.0170 - val_loss: 3.3002e-04 - val_mae: 0.0120\n",
      "Epoch 283/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 5.2581e-04 - mae: 0.0149 - val_loss: 5.3831e-04 - val_mae: 0.0136\n",
      "Epoch 284/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.8780e-04 - mae: 0.0144 - val_loss: 3.3014e-04 - val_mae: 0.0117\n",
      "Epoch 285/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1757e-04 - mae: 0.0162 - val_loss: 3.5918e-04 - val_mae: 0.0122\n",
      "Epoch 286/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.5564e-04 - mae: 0.0137 - val_loss: 3.7024e-04 - val_mae: 0.0128\n",
      "Epoch 287/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.1449e-04 - mae: 0.0132 - val_loss: 3.0850e-04 - val_mae: 0.0121\n",
      "Epoch 288/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.2368e-04 - mae: 0.0134 - val_loss: 3.8388e-04 - val_mae: 0.0126\n",
      "Epoch 289/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.8897e-04 - mae: 0.0169 - val_loss: 3.3738e-04 - val_mae: 0.0122\n",
      "Epoch 290/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0198 - val_loss: 5.1129e-04 - val_mae: 0.0149\n",
      "Epoch 291/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.0411e-04 - mae: 0.0148 - val_loss: 4.0110e-04 - val_mae: 0.0132\n",
      "Epoch 292/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.6262e-04 - mae: 0.0124 - val_loss: 3.4689e-04 - val_mae: 0.0121\n",
      "Epoch 293/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.9702e-04 - mae: 0.0129 - val_loss: 4.7196e-04 - val_mae: 0.0148\n",
      "Epoch 294/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.1184e-04 - mae: 0.0163 - val_loss: 3.4323e-04 - val_mae: 0.0124\n",
      "Epoch 295/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8974e-04 - mae: 0.0145 - val_loss: 3.6814e-04 - val_mae: 0.0126\n",
      "Epoch 296/1000\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 3.9151e-04 - mae: 0.0129 - val_loss: 5.0393e-04 - val_mae: 0.0139\n",
      "Epoch 297/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.8185e-04 - mae: 0.0156 - val_loss: 0.0011 - val_mae: 0.0208\n",
      "Epoch 298/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.0945e-04 - mae: 0.0149 - val_loss: 3.7809e-04 - val_mae: 0.0124\n",
      "Epoch 299/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.0358e-04 - mae: 0.0132 - val_loss: 5.4421e-04 - val_mae: 0.0148\n",
      "Epoch 300/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2449e-04 - mae: 0.0134 - val_loss: 2.9973e-04 - val_mae: 0.0113\n",
      "Epoch 301/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8936e-04 - mae: 0.0127 - val_loss: 2.9855e-04 - val_mae: 0.0113\n",
      "Epoch 302/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.5477e-04 - mae: 0.0140 - val_loss: 6.5748e-04 - val_mae: 0.0158\n",
      "Epoch 303/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6713e-04 - mae: 0.0157 - val_loss: 6.4040e-04 - val_mae: 0.0162\n",
      "Epoch 304/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 3.8910e-04 - mae: 0.0130 - val_loss: 4.3604e-04 - val_mae: 0.0121\n",
      "Epoch 305/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 5.5462e-04 - mae: 0.0154 - val_loss: 3.3193e-04 - val_mae: 0.0122\n",
      "Epoch 306/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.5127e-04 - mae: 0.0142 - val_loss: 4.2249e-04 - val_mae: 0.0148\n",
      "Epoch 307/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0051e-04 - mae: 0.0132 - val_loss: 4.3011e-04 - val_mae: 0.0146\n",
      "Epoch 308/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.1272e-04 - mae: 0.0133 - val_loss: 3.6739e-04 - val_mae: 0.0123\n",
      "Epoch 309/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.1705e-04 - mae: 0.0137 - val_loss: 3.6093e-04 - val_mae: 0.0114\n",
      "Epoch 310/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 6.1514e-04 - mae: 0.0159 - val_loss: 9.7996e-04 - val_mae: 0.0200\n",
      "Epoch 311/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 6.7631e-04 - mae: 0.0171 - val_loss: 3.2913e-04 - val_mae: 0.0131\n",
      "Epoch 312/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.9064e-04 - mae: 0.0130 - val_loss: 3.7698e-04 - val_mae: 0.0136\n",
      "Epoch 313/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0243e-04 - mae: 0.0132 - val_loss: 4.1419e-04 - val_mae: 0.0149\n",
      "Epoch 314/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.3870e-04 - mae: 0.0138 - val_loss: 3.1872e-04 - val_mae: 0.0126\n",
      "Epoch 315/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 4.4741e-04 - mae: 0.0141 - val_loss: 3.3191e-04 - val_mae: 0.0122\n",
      "Epoch 316/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 4.4027e-04 - mae: 0.0137 - val_loss: 3.3402e-04 - val_mae: 0.0124\n",
      "Epoch 317/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2506e-04 - mae: 0.0151 - val_loss: 5.5647e-04 - val_mae: 0.0169\n",
      "Epoch 318/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.2088e-04 - mae: 0.0138 - val_loss: 3.5757e-04 - val_mae: 0.0133\n",
      "Epoch 319/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.1852e-04 - mae: 0.0152 - val_loss: 5.6695e-04 - val_mae: 0.0148\n",
      "Epoch 320/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1356e-04 - mae: 0.0136 - val_loss: 4.2896e-04 - val_mae: 0.0148\n",
      "Epoch 321/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 5.1819e-04 - mae: 0.0145 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 322/1000\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 6.5976e-04 - mae: 0.0169 - val_loss: 4.5211e-04 - val_mae: 0.0146\n",
      "Epoch 323/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.6519e-04 - mae: 0.0125 - val_loss: 5.1102e-04 - val_mae: 0.0162\n",
      "Epoch 324/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2390e-04 - mae: 0.0135 - val_loss: 3.5657e-04 - val_mae: 0.0120\n",
      "Epoch 325/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5574e-04 - mae: 0.0123 - val_loss: 4.1139e-04 - val_mae: 0.0143\n",
      "Epoch 326/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.0588e-04 - mae: 0.0133 - val_loss: 3.7202e-04 - val_mae: 0.0125\n",
      "Epoch 327/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 4.1919e-04 - mae: 0.0137 - val_loss: 2.6389e-04 - val_mae: 0.0107\n",
      "Epoch 328/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.7380e-04 - mae: 0.0126 - val_loss: 3.0898e-04 - val_mae: 0.0115\n",
      "Epoch 329/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6359e-04 - mae: 0.0124 - val_loss: 3.1185e-04 - val_mae: 0.0117\n",
      "Epoch 330/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8440e-04 - mae: 0.0145 - val_loss: 7.3672e-04 - val_mae: 0.0154\n",
      "Epoch 331/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.0356e-04 - mae: 0.0149 - val_loss: 4.9212e-04 - val_mae: 0.0137\n",
      "Epoch 332/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.1421e-04 - mae: 0.0134 - val_loss: 3.3748e-04 - val_mae: 0.0120\n",
      "Epoch 333/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4150e-04 - mae: 0.0137 - val_loss: 3.7626e-04 - val_mae: 0.0122\n",
      "Epoch 334/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.4479e-04 - mae: 0.0134 - val_loss: 0.0010 - val_mae: 0.0176\n",
      "Epoch 335/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 8.1237e-04 - mae: 0.0176 - val_loss: 3.6606e-04 - val_mae: 0.0126\n",
      "Epoch 336/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.4913e-04 - mae: 0.0138 - val_loss: 3.7988e-04 - val_mae: 0.0131\n",
      "Epoch 337/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 4.3625e-04 - mae: 0.0134 - val_loss: 3.4046e-04 - val_mae: 0.0134\n",
      "Epoch 338/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.5193e-04 - mae: 0.0121 - val_loss: 2.6661e-04 - val_mae: 0.0111\n",
      "Epoch 339/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6821e-04 - mae: 0.0127 - val_loss: 3.5644e-04 - val_mae: 0.0128\n",
      "Epoch 340/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.4722e-04 - mae: 0.0137 - val_loss: 3.1475e-04 - val_mae: 0.0124\n",
      "Epoch 341/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.6454e-04 - mae: 0.0138 - val_loss: 3.2550e-04 - val_mae: 0.0122\n",
      "Epoch 342/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4364e-04 - mae: 0.0119 - val_loss: 8.0423e-04 - val_mae: 0.0154\n",
      "Epoch 343/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.7269e-04 - mae: 0.0144 - val_loss: 4.1134e-04 - val_mae: 0.0125\n",
      "Epoch 344/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.2239e-04 - mae: 0.0135 - val_loss: 4.1769e-04 - val_mae: 0.0132\n",
      "Epoch 345/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.9939e-04 - mae: 0.0128 - val_loss: 5.4257e-04 - val_mae: 0.0147\n",
      "Epoch 346/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 4.9048e-04 - mae: 0.0151 - val_loss: 4.3144e-04 - val_mae: 0.0132\n",
      "Epoch 347/1000\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 4.1485e-04 - mae: 0.0136 - val_loss: 2.5824e-04 - val_mae: 0.0104\n",
      "Epoch 348/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.2593e-04 - mae: 0.0117 - val_loss: 3.0406e-04 - val_mae: 0.0106\n",
      "Epoch 349/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.8335e-04 - mae: 0.0166 - val_loss: 5.0164e-04 - val_mae: 0.0157\n",
      "Epoch 350/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5735e-04 - mae: 0.0120 - val_loss: 2.4742e-04 - val_mae: 0.0102\n",
      "Epoch 351/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6342e-04 - mae: 0.0121 - val_loss: 4.2570e-04 - val_mae: 0.0141\n",
      "Epoch 352/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.6286e-04 - mae: 0.0124 - val_loss: 2.9488e-04 - val_mae: 0.0109\n",
      "Epoch 353/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6158e-04 - mae: 0.0123 - val_loss: 3.8451e-04 - val_mae: 0.0141\n",
      "Epoch 354/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 4.7866e-04 - mae: 0.0144 - val_loss: 6.2526e-04 - val_mae: 0.0156\n",
      "Epoch 355/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 7.0905e-04 - mae: 0.0174 - val_loss: 4.0156e-04 - val_mae: 0.0149\n",
      "Epoch 356/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.5015e-04 - mae: 0.0124 - val_loss: 4.3262e-04 - val_mae: 0.0137\n",
      "Epoch 357/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.3544e-04 - mae: 0.0118 - val_loss: 2.5756e-04 - val_mae: 0.0109\n",
      "Epoch 358/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8052e-04 - mae: 0.0140 - val_loss: 4.1339e-04 - val_mae: 0.0129\n",
      "Epoch 359/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4692e-04 - mae: 0.0121 - val_loss: 2.9897e-04 - val_mae: 0.0108\n",
      "Epoch 360/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.5392e-04 - mae: 0.0121 - val_loss: 3.2293e-04 - val_mae: 0.0124\n",
      "Epoch 361/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 7.2788e-04 - mae: 0.0173 - val_loss: 3.9219e-04 - val_mae: 0.0126\n",
      "Epoch 362/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.2051e-04 - mae: 0.0115 - val_loss: 4.0241e-04 - val_mae: 0.0132\n",
      "Epoch 363/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 3.3655e-04 - mae: 0.0120 - val_loss: 2.9293e-04 - val_mae: 0.0111\n",
      "Epoch 364/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2222e-04 - mae: 0.0114 - val_loss: 2.8460e-04 - val_mae: 0.0104\n",
      "Epoch 365/1000\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 3.6097e-04 - mae: 0.0119 - val_loss: 5.1304e-04 - val_mae: 0.0138\n",
      "Epoch 366/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.7455e-04 - mae: 0.0127 - val_loss: 2.8327e-04 - val_mae: 0.0110\n",
      "Epoch 367/1000\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 3.9775e-04 - mae: 0.0129 - val_loss: 4.2601e-04 - val_mae: 0.0142\n",
      "Epoch 368/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.1784e-04 - mae: 0.0137 - val_loss: 2.9309e-04 - val_mae: 0.0113\n",
      "Epoch 369/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7815e-04 - mae: 0.0126 - val_loss: 3.8813e-04 - val_mae: 0.0136\n",
      "Epoch 370/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.1573e-04 - mae: 0.0116 - val_loss: 3.2853e-04 - val_mae: 0.0116\n",
      "Epoch 371/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.4196e-04 - mae: 0.0123 - val_loss: 6.6703e-04 - val_mae: 0.0158\n",
      "Epoch 372/1000\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 3.2995e-04 - mae: 0.0117 - val_loss: 3.5727e-04 - val_mae: 0.0127\n",
      "Epoch 373/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 6.5253e-04 - mae: 0.0164 - val_loss: 4.0087e-04 - val_mae: 0.0122\n",
      "Epoch 374/1000\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.9860e-04 - mae: 0.0133 - val_loss: 3.7190e-04 - val_mae: 0.0135\n",
      "Epoch 375/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.1692e-04 - mae: 0.0117 - val_loss: 3.1957e-04 - val_mae: 0.0115\n",
      "Epoch 376/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6487e-04 - mae: 0.0123 - val_loss: 3.9641e-04 - val_mae: 0.0138\n",
      "Epoch 377/1000\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.7073e-04 - mae: 0.0126 - val_loss: 3.0005e-04 - val_mae: 0.0109\n",
      "Epoch 378/1000\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8986e-04 - mae: 0.0108 - val_loss: 3.4742e-04 - val_mae: 0.0130\n",
      "Epoch 379/1000\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 5.0467e-04 - mae: 0.0148 - val_loss: 3.2290e-04 - val_mae: 0.0123\n",
      "Epoch 380/1000\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 3.4452e-04 - mae: 0.0119 - val_loss: 3.9346e-04 - val_mae: 0.0135\n",
      "Epoch 380: early stopping\n",
      "Loss: 0.0003934648120775819, MAE: 0.01353535894304514\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "R² score for output 1: 0.9997955822416894\n",
      "R² score for output 2: 0.9994510932947419\n",
      "R² score for output 3: 0.9994784209915113\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "scalery = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scalery.fit_transform(y_train)\n",
    "y_test = scalery.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='linear')  # 3 outputs: cl, cd, cm\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test,y_test), callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss}, MAE: {mae}\")\n",
    "\n",
    "# CNN2: Loss: 0.0032769939862191677, MAE: 0.038386013358831406\n",
    "# CNN3: Loss: 0.0012407711474224925, MAE: 0.025044899433851242\n",
    "# CNN4: Loss: 0.0007000479381531477, MAE: 0.017104944214224815\n",
    "# CNN5: Loss: 0.0006939252489246428, MAE: 0.016976164653897285\n",
    "# CNN6: Loss: 0.0005698658060282469, MAE: 0.01500221062451601\n",
    "# CNN7：Loss: 0.0002656226570252329, MAE: 0.009741054847836494 (final model)\n",
    "# CNN8: Loss: 0.0003934648120775819, MAE: 0.01353535894304514 (seems better at high mach numbers)\n",
    "\n",
    "# R2-score\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scalery.inverse_transform(y_pred)\n",
    "y_test = scalery.inverse_transform(y_test)\n",
    "r2_scores = [r2_score(y_test[:, i], y_pred[:, i]) for i in range(y_test.shape[1])]\n",
    "for i, r2 in enumerate(r2_scores):\n",
    "    print(f\"R² score for output {i+1}: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               512       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,539\n",
      "Trainable params: 11,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss curve\n",
    "losses = pd.DataFrame(history.history)\n",
    "plt.plot(losses.index, losses['loss'], label='train_loss')\n",
    "plt.plot(losses.index, losses['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file\n",
    "model.save('clark-y-cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
